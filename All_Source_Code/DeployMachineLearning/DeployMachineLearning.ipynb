{"nbformat": 4, "nbformat_minor": 2, "cells": [{"metadata": {}, "source": ["### Machine Learning for Engineers: [DeployMachineLearning](https://www.apmonitor.com/pds/index.php/Main/DeployMachineLearning)\n- [Deploy Machine Learning](https://www.apmonitor.com/pds/index.php/Main/DeployMachineLearning)\n - Source Blocks: 10\n - Description: Deploying machine learning is the process of making the machine learning solution available to produce results for people or computers to access the service remotely.\n- [Course Overview](https://apmonitor.com/pds)\n- [Course Schedule](https://apmonitor.com/pds/index.php/Main/CourseSchedule)\n"], "cell_type": "markdown"}, {"metadata": {}, "outputs": [], "source": ["z = [1,2,3]\n\nimport pickle\npickle.dump(z,open('z.pkl','wb'))"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "outputs": [], "source": ["import pickle\ny = pickle.load(open('z.pkl','rb'))\nprint(y)"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "outputs": [], "source": ["model.save('store.h5')"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "outputs": [], "source": ["from keras.models import load_model\nmodel = load_model('store.h5')"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "outputs": [], "source": ["# Generate blobs dataset\nfrom sklearn.datasets import make_blobs\nfeatures, label = make_blobs(n_samples=1000, centers=2,\\\n                             n_features=2, random_state=12)\n\n# Split into train and test subsets (20% for test)\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(\n    features, label, test_size=0.2, shuffle=False)\n\n# Train Logistic Regression model\nfrom sklearn.linear_model import LogisticRegression\nlr = LogisticRegression(solver='lbfgs')\nlr.fit(X_train,y_train)\n\n# Store model and test data\nimport pickle\nstore = [lr,X_test,y_test]\npickle.dump(store,open('store.pkl','wb'))\n\n# View data\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\ndata = pd.DataFrame({'x1':features[:,0],\n                     'x2':features[:,1],\n                     'y':label})\nsns.pairplot(data,hue='y')\nplt.show()"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "outputs": [], "source": ["# Retrieve model and test data\nimport pickle\n[lr,X_test,y_test] = pickle.load(open('store.pkl','rb'))\n\n# Predict\ny_predict = lr.predict(X_test)\n\n# Generate confusion matrix\nfrom sklearn.metrics import confusion_matrix\nimport seaborn as sns\nimport matplotlib.pyplot as plt\ncmat = confusion_matrix(y_test,y_predict)\nsns.heatmap(cmat,annot=True)\nplt.show()"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "outputs": [], "source": ["from sklearn import datasets\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nfrom sklearn.neural_network import MLPClassifier\nclassifier = MLPClassifier(solver='lbfgs',alpha=1e-5,max_iter=200,\\\n                    activation='relu',hidden_layer_sizes=(10,30,10),\\\n                    random_state=1, shuffle=True)\n\n# The digits dataset\ndigits = datasets.load_digits()\nn_samples = len(digits.images)\ndata = digits.images.reshape((n_samples, -1))\n\n# Split into train and test subsets (50% each)\nX_train, X_test, y_train, y_test = train_test_split(\n    data, digits.target, test_size=0.5, shuffle=False)\n\n# Learn the digits on the first half of the digits\nclassifier.fit(X_train, y_train)\n\n# Test on second half of data\nn = np.random.randint(int(n_samples/2),n_samples)\nprint('Predicted: ' + str(classifier.predict(digits.data[n:n+1])[0]))\n\n# Show number\nplt.imshow(digits.images[n], cmap=plt.cm.gray_r, interpolation='nearest')\nplt.show()"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "outputs": [], "source": ["from sklearn import datasets\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nfrom sklearn.neighbors import KNeighborsClassifier\nclassifier = KNeighborsClassifier(n_neighbors=5)\n\n# The digits dataset\ndigits = datasets.load_digits()\nn_samples = len(digits.images)\ndata = digits.images.reshape((n_samples, -1))\n\n# Split into train and test subsets (50% each)\nX_train, X_test, y_train, y_test = train_test_split(\n    data, digits.target, test_size=0.5, shuffle=False)\n\n# Learn the digits on the first half of the digits\nclassifier.fit(X_train, y_train)\n\n# Store model and test data\nimport pickle\nstore = [classifier,digits]\npickle.dump(store,open('store.pkl','wb'))"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "outputs": [], "source": ["# Retrieve model and test data\nimport pickle\n[classifier,digits] = pickle.load(open('store.pkl','rb'))\n\n# Test on second to last number\nprint('Predicted: ' + str(classifier.predict(digits.data[-2:-1])[0]))\n\n# Show number\nplt.imshow(digits.images[-2], cmap=plt.cm.gray_r, interpolation='nearest')\nplt.show()"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "outputs": [], "source": ["from os.path import exists\nimport pickle\nimport numpy as np\nfrom gekko import GEKKO\nimport matplotlib.pyplot as plt\n\nif exists('m.pkl'):\n    # load model from subsequent call\n    m = pickle.load(open('m.pkl','rb'))\n    m.solve()\nelse:\n    # define model the first time\n    m = GEKKO()\n    m.time = np.linspace(0,20,41)\n\n    m.p = m.MV(value=0, lb=0, ub=1)\n    m.v = m.CV(value=0)\n    m.Equation(5*m.v.dt() == -m.v + 10*m.p)\n    m.options.IMODE = 6\n    m.p.STATUS = 1; m.p.DCOST = 1e-3\n    m.v.STATUS = 1; m.v.SP = 40; m.v.TAU = 5\n    m.options.CV_TYPE = 2\n    m.solve()\npickle.dump(m,open('m.pkl','wb'))\n\nplt.figure()\nplt.subplot(2,1,1)\nplt.plot(m.time,m.p.value,'b-',lw=2)\nplt.ylabel('gas')\nplt.subplot(2,1,2)\nplt.plot(m.time,m.v.value,'r--',lw=2)\nplt.ylabel('velocity')\nplt.xlabel('time')\nplt.show()"], "execution_count": null, "cell_type": "code"}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}}}