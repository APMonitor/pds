{"nbformat": 4, "nbformat_minor": 2, "cells": [{"metadata": {}, "source": ["### Machine Learning for Engineers: [FacialRecognition](https://www.apmonitor.com/pds/index.php/Main/FacialRecognition)\n- [Facial Recognition](https://www.apmonitor.com/pds/index.php/Main/FacialRecognition)\n - Source Blocks: 8\n - Description: Use computer vision and deep learning to detect faces, recognize the class participant, record attendance, and send a customized message to students who missed class that day.\n- [Course Overview](https://apmonitor.com/pds)\n- [Course Schedule](https://apmonitor.com/pds/index.php/Main/CourseSchedule)\n"], "cell_type": "markdown"}, {"metadata": {}, "outputs": [], "source": ["import cv2\nimport mediapipe as mp\nmp_face_detection = mp.solutions.face_detection\nmp_drawing = mp.solutions.drawing_utils\nimport urllib.request\n\n# download image as class.jpg\nurl = 'http://apmonitor.com/pds/uploads/Main/students_walking.jpg'\nurllib.request.urlretrieve(url, 'class.jpg')\nIMAGE_FILES = ['class.jpg']\nwith mp_face_detection.FaceDetection(\n    model_selection=1, min_detection_confidence=0.5) as face_detection:\n  for idx, file in enumerate(IMAGE_FILES):\n    image = cv2.imread(file)\n    # Convert the BGR image to RGB and process it with MediaPipe Face Detection.\n    results = face_detection.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n\n    # Draw face detections of each face.\n    if not results.detections:\n      continue\n    annotated_image = image.copy()\n    for detection in results.detections:\n      print('Nose tip:')\n      print(mp_face_detection.get_key_point(\n          detection, mp_face_detection.FaceKeyPoint.NOSE_TIP))\n      mp_drawing.draw_detection(annotated_image, detection)\n    cv2.imwrite('annotated_image' + str(idx) + '.png', annotated_image)"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "outputs": [], "source": ["import cv2\nimport mediapipe as mp\nmp_face_detection = mp.solutions.face_detection\nmp_drawing = mp.solutions.drawing_utils\n\n# webcam input\ncap = cv2.VideoCapture(0)\nwith mp_face_detection.FaceDetection(\n    model_selection=0, min_detection_confidence=0.5) as face_detection:\n  while cap.isOpened():\n    success, image = cap.read()\n    if not success:\n      print(\"Ignoring empty camera frame.\")\n      # If loading a video, use 'break' instead of 'continue'.\n      continue\n\n    # To improve performance, optionally mark the image as not writeable to\n    # pass by reference.\n    image.flags.writeable = False\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    results = face_detection.process(image)\n\n    # Draw the face detection annotations on the image.\n    image.flags.writeable = True\n    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n    if results.detections:\n      for detection in results.detections:\n        mp_drawing.draw_detection(image, detection)\n    # Flip the image horizontally for a selfie-view display.\n    cv2.imshow('MediaPipe Face Detection', cv2.flip(image, 1))\n    if cv2.waitKey(5) & 0xFF == 27:\n      break\ncap.release()"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "outputs": [], "source": ["import matplotlib.pyplot as plt\nfrom mtcnn.mtcnn import MTCNN\nimport urllib.request\n\n# download image as class.jpg\nurl = 'http://apmonitor.com/pds/uploads/Main/students_walking.jpg'\nurllib.request.urlretrieve(url, 'class.jpg')\n\ndef draw_faces(data, result_list):\n    for i in range(len(result_list)):\n        x1, y1, width, height = result_list[i]['box']\n        x2, y2 = x1 + width, y1 + height\n        plt.subplot(1, len(result_list), i+1)\n        plt.axis('off')\n        plt.imshow(data[y1:y2, x1:x2])\n    plt.show()\n\npixels = plt.imread('class.jpg')      # read image\ndetector = MTCNN()                    # create detector\nfaces = detector.detect_faces(pixels) # detect faces\ndraw_faces(pixels, faces)             # display faces"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "outputs": [], "source": ["for x in faces:\n    print(x['confidence'])"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "outputs": [], "source": ["import matplotlib.pyplot as plt\nimport matplotlib.patches as patches\nimport cv2\nimport urllib.request\n\n# download image as class.jpg\nurl = 'http://apmonitor.com/pds/uploads/Main/students_walking.jpg'\nurllib.request.urlretrieve(url, 'class.jpg')\n\n# download cascade classifier configuration\nurl = 'http://apmonitor.com/pds/uploads/Main/cascade.xml'\nurllib.request.urlretrieve(url, 'cascade.xml')\n\ndef draw_faces(data, result_list):\n    for i in range(len(result_list)):\n        x1, y1, width, height = result_list[i]\n        x2, y2 = x1 + width, y1 + height\n        plt.subplot(1, len(result_list), i+1)\n        plt.axis('off')\n        plt.imshow(data[y1:y2, x1:x2])\n\npixels = plt.imread('class.jpg')\nfaceCascade = cv2.CascadeClassifier('cascade.xml')\ngray = cv2.cvtColor(pixels, cv2.COLOR_BGR2GRAY)\nfaces = faceCascade.detectMultiScale(gray,scaleFactor=1.1,\n                                     minNeighbors=2,\\\n                                     minSize=(10, 10))\n\n# display only the faces\ndraw_faces(pixels, faces)             \n\n# display identified faces on original image\nfig, ax = plt.subplots(); ax.imshow(pixels)\nfor (x, y, w, h) in faces:\n    rect = patches.Rectangle((x, y), w, h, lw=2, \\\n                             alpha=0.5, edgecolor='r', \\\n                             facecolor='none')\n    ax.add_patch(rect)\n\nplt.show()"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "outputs": [], "source": ["import cv2\nimport time\nimport urllib.request\n\n# download cascade classifier configuration\nurl = 'http://apmonitor.com/pds/uploads/Main/cascade.xml'\nurllib.request.urlretrieve(url, 'cascade.xml')\n\nfaceCascade = cv2.CascadeClassifier('cascade.xml')\nvideo_capture = cv2.VideoCapture(0)\n\nt = time.time()\nwhile time.time()-t <=20: # run for max 20 sec\n    ret, frame = video_capture.read()\n    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n    faces = faceCascade.detectMultiScale(gray,scaleFactor=1.1,\n        minNeighbors=5,minSize=(30, 30))\n    for (x, y, w, h) in faces:\n        cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n    cv2.imshow('Video', frame)\n\n    if cv2.waitKey(1) & 0xFF == ord('q'):\n        break\nvideo_capture.release()\ncv2.destroyAllWindows()"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "outputs": [], "source": ["import pandas as pd\nimport smtplib\nfrom email.mime.text import MIMEText\nfrom getpass import getpass\n\nask = False\nif ask:\n    From = input(\"Enter email address of the sender: \")\n    username = input(\"Enter email user name: \")\n    smtp_server = input(\"Enter SMTP server address: \")\n    password = getpass(\"Password for \"+username+\" at \"+smtp_server+\": \")\nelse:\n    From ='Instructor <instructor@example.com>'\n    username ='my_username'\n    smtp_server ='mail.et.byu.edu'\n    password = '1234' # not good practice to put password in the code\n\nurl = 'http://apmonitor.com/pds/uploads/Main/students.txt'\nstudents = pd.read_csv(url)\n\ndef sendEmail(Subject, bodyText, To, pw):\n    msg = MIMEText(bodyText)\n    msg['Subject'] = Subject\n    msg['From']    = From\n    msg['To']      = To\n\n    server = smtplib.SMTP(smtp_server)\n    server.starttls()\n    server.login(username, password)\n    server.send_message(msg)\n    server.quit()\n\n    return 'Sent to ' + To\n\nMessage = '''We missed you in class today. I hope you are doing well.\n\nToday we worked on the project for facial recognition.\n\nBest regards,\n\nJohn Hedengren\nBrigham Young University'''\n\nfor i in range(len(students)):\n    bdTxt = students.First[i] + ',\\n\\n' + Message\n\n    To = students.Email[i]\n    print(To)\n    Subject = \"Hi \" + students.First[i] + \", we missed you today\"\n    sendEmail(Subject,bdTxt,To,password)"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "outputs": [], "source": ["import pyttsx3\nname = 'Peter'\nengine = pyttsx3.init()\nengine.say(\"Welcome to class, \"+name)\nengine.runAndWait()"], "execution_count": null, "cell_type": "code"}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}}}