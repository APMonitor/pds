{"nbformat": 4, "nbformat_minor": 2, "cells": [{"metadata": {}, "source": ["### Machine Learning for Engineers: [LogisticRegression](https://www.apmonitor.com/pds/index.php/Main/LogisticRegression)\n- [Logistic Regression](https://www.apmonitor.com/pds/index.php/Main/LogisticRegression)\n - Source Blocks: 7\n - Description: Introduction to Logistic Regression\n- [Course Overview](https://apmonitor.com/pds)\n- [Course Schedule](https://apmonitor.com/pds/index.php/Main/CourseSchedule)\n"], "cell_type": "markdown"}, {"metadata": {}, "outputs": [], "source": ["from sklearn.linear_model import LogisticRegression\nlr = LogisticRegression(solver='lbfgs')\nlr.fit(XA,yA)\nyP = lr.predict(XB)"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "outputs": [], "source": ["from sklearn import datasets\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nfrom sklearn.linear_model import LogisticRegression\nclassifier = LogisticRegression(solver='lbfgs')\n\n# The digits dataset\ndigits = datasets.load_digits()\nn_samples = len(digits.images)\ndata = digits.images.reshape((n_samples, -1))\n\n# Split into train and test subsets (50% each)\nX_train, X_test, y_train, y_test = train_test_split(\n    data, digits.target, test_size=0.5, shuffle=False)\n\n# Learn the digits on the first half of the digits\nclassifier.fit(X_train, y_train)\n\n# Test on second half of data\nn = np.random.randint(int(n_samples/2),n_samples)\nprint('Predicted: ' + str(classifier.predict(digits.data[n:n+1])[0]))\n\n# Show number\nplt.imshow(digits.images[n], cmap=plt.cm.gray_r, interpolation='nearest')\nplt.show()"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "outputs": [], "source": ["import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.datasets import make_blobs\nimport seaborn as sns\n\n# Generate blobs dataset\nfeatures, label = make_blobs(n_samples=800, centers=2,\\\n                             n_features=2, random_state=12) \ndata = pd.DataFrame()\ndata['x1'] = features[:,0]\ndata['x2'] = features[:,1]\ndata['y']  = label\n\nsns.pairplot(data,hue='y')"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "outputs": [], "source": ["from sklearn.model_selection import train_test_split\ntrain, test = train_test_split(data.values,test_size=0.2)"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "outputs": [], "source": ["from math import exp\ndef predict(row, beta):\n    x = row[0:2]\n    yhat = beta[0] + beta[1]*x[0] + beta[2]*x[1]\n    return 1.0 / (1.0 + exp(-yhat))"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "outputs": [], "source": ["l_rate = 0.3\nn_epoch = 100\n\nloss = np.zeros(n_epoch)\nbeta = [0.0,0.0,0.0]\nfor epoch in range(n_epoch):\n    sum_error = 0\n    for row in train:\n        x = row[0:-1] # input features\n        y = row[-1]   # output label\n        yhat = predict(row, beta)\n        error = y - yhat\n        sum_error += error**2\n        beta[0] += l_rate * error * yhat * (1.0 - yhat)\n        beta[1] += l_rate * error * yhat * (1.0 - yhat) * x[0]\n        beta[2] += l_rate * error * yhat * (1.0 - yhat) * x[1]\n    loss[epoch] = sum_error\n\nprint('Coefficients:',beta)\nplt.plot(loss)\nplt.xlabel('Epoch')\nplt.ylabel('Loss')"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "outputs": [], "source": ["yhat = []\nfor row in test:\n    yhat.append(round(predict(row, beta)))\n\nfrom sklearn.metrics import confusion_matrix\ncmat = confusion_matrix(test[:,-1],yhat)\nsns.heatmap(cmat,annot=True)"], "execution_count": null, "cell_type": "code"}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}}}