{"nbformat": 4, "nbformat_minor": 2, "cells": [{"metadata": {}, "source": ["### Machine Learning for Engineers: [LongShortTermMemory](https://www.apmonitor.com/pds/index.php/Main/LongShortTermMemory)\n- [LSTM Networks](https://www.apmonitor.com/pds/index.php/Main/LongShortTermMemory)\n - Source Blocks: 10\n - Description: Long-Short Term Memory (LSTM), Recurrent Neural Networks, and other sequential processing methods consider a window of data to make a future prediction.\n- [Course Overview](https://apmonitor.com/pds)\n- [Course Schedule](https://apmonitor.com/pds/index.php/Main/CourseSchedule)\n"], "cell_type": "markdown"}, {"metadata": {}, "outputs": [], "source": ["import numpy as np\nimport matplotlib.pyplot as plt\n\n# Generate data\nn = 500\nt = np.linspace(0,20.0*np.pi,n)\nX = np.sin(t) # X is already between -1 and 1, scaling normally needed"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "outputs": [], "source": ["# Set window of past points for LSTM model\nwindow = 10 \n\n# Split 80/20 into train/test data\nlast = int(n/5.0)\nXtrain = X[:-last]\nXtest = X[-last-window:]\n\n# Store window number of points as a sequence\nxin = []\nnext_X = []\nfor i in range(window,len(Xtrain)):\n    xin.append(Xtrain[i-window:i])\n    next_X.append(Xtrain[i])\n\n# Reshape data to format for LSTM\nxin, next_X = np.array(xin), np.array(next_X)\nxin = xin.reshape(xin.shape[0], xin.shape[1], 1)"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "outputs": [], "source": ["from keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nfrom keras.layers import Dropout\n\n# Initialize LSTM model\nm = Sequential()\nm.add(LSTM(units=50, return_sequences=True, input_shape=(xin.shape[1],1)))\nm.add(Dropout(0.2))\nm.add(LSTM(units=50))\nm.add(Dropout(0.2))\nm.add(Dense(units=1))\nm.compile(optimizer = 'adam', loss = 'mean_squared_error')"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "outputs": [], "source": ["# Fit LSTM model\nhistory = m.fit(xin, next_X, epochs = 50, batch_size = 50,verbose=0)\n\nplt.figure()\nplt.ylabel('loss'); plt.xlabel('epoch')\nplt.semilogy(history.history['loss'])"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "outputs": [], "source": ["# Store \"window\" points as a sequence\nxin = []\nnext_X1 = []\nfor i in range(window,len(Xtest)):\n    xin.append(Xtest[i-window:i])\n    next_X1.append(Xtest[i])\n\n# Reshape data to format for LSTM\nxin, next_X1 = np.array(xin), np.array(next_X1)\nxin = xin.reshape((xin.shape[0], xin.shape[1], 1))\n\n# Predict the next value (1 step ahead)\nX_pred = m.predict(xin)\n\n# Plot prediction vs actual for test data\nplt.figure()\nplt.plot(X_pred,':',label='LSTM')\nplt.plot(next_X1,'--',label='Actual')\nplt.legend()"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "outputs": [], "source": ["# Using predicted values to predict next step\nX_pred = Xtest.copy()\nfor i in range(window,len(X_pred)):\n    xin = X_pred[i-window:i].reshape((1, window, 1))\n    X_pred[i] = m.predict(xin)\n\n# Plot prediction vs actual for test data\nplt.figure()\nplt.plot(X_pred[window:],':',label='LSTM')\nplt.plot(next_X1,'--',label='Actual')\nplt.legend()"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "outputs": [], "source": ["import numpy as np\nimport matplotlib.pyplot as plt\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nfrom keras.layers import Dropout\n\n# Generate data\nn = 500\nt = np.linspace(0,20.0*np.pi,n)\nX = np.sin(t) # X is already between -1 and 1, scaling normally needed\n\n# Set window of past points for LSTM model\nwindow = 10 \n\n# Split 80/20 into train/test data\nlast = int(n/5.0)\nXtrain = X[:-last]\nXtest = X[-last-window:]\n\n# Store window number of points as a sequence\nxin = []\nnext_X = []\nfor i in range(window,len(Xtrain)):\n    xin.append(Xtrain[i-window:i])\n    next_X.append(Xtrain[i])\n\n# Reshape data to format for LSTM\nxin, next_X = np.array(xin), np.array(next_X)\nxin = xin.reshape(xin.shape[0], xin.shape[1], 1)\n\n# Initialize LSTM model\nm = Sequential()\nm.add(LSTM(units=50, return_sequences=True, input_shape=(xin.shape[1],1)))\nm.add(Dropout(0.2))\nm.add(LSTM(units=50))\nm.add(Dropout(0.2))\nm.add(Dense(units=1))\nm.compile(optimizer = 'adam', loss = 'mean_squared_error')\n\n# Fit LSTM model\nhistory = m.fit(xin, next_X, epochs = 50, batch_size = 50,verbose=0)\n\nplt.figure()\nplt.ylabel('loss'); plt.xlabel('epoch')\nplt.semilogy(history.history['loss'])\n\n# Store \"window\" points as a sequence\nxin = []\nnext_X1 = []\nfor i in range(window,len(Xtest)):\n    xin.append(Xtest[i-window:i])\n    next_X1.append(Xtest[i])\n\n# Reshape data to format for LSTM\nxin, next_X1 = np.array(xin), np.array(next_X1)\nxin = xin.reshape((xin.shape[0], xin.shape[1], 1))\n\n# Predict the next value (1 step ahead)\nX_pred = m.predict(xin)\n\n# Plot prediction vs actual for test data\nplt.figure()\nplt.plot(X_pred,':',label='LSTM')\nplt.plot(next_X1,'--',label='Actual')\nplt.legend()\n\n# Using predicted values to predict next step\nX_pred = Xtest.copy()\nfor i in range(window,len(X_pred)):\n    xin = X_pred[i-window:i].reshape((1, window, 1))\n    X_pred[i] = m.predict(xin)\n\n# Plot prediction vs actual for test data\nplt.figure()\nplt.plot(X_pred[window:],':',label='LSTM')\nplt.plot(next_X1,'--',label='Actual')\nplt.legend()\nplt.show()"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "outputs": [], "source": ["# generate new data\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport tclab\nimport time\n\nn = 840  # Number of second time points (14 min)\ntm = np.linspace(0,n,n+1) # Time values\nlab = tclab.TCLab()\nT1 = [lab.T1]\nT2 = [lab.T2]\nQ1 = np.zeros(n+1)\nQ2 = np.zeros(n+1)\nQ1[30:] = 35.0\nQ1[270:] = 70.0\nQ1[450:] = 10.0\nQ1[630:] = 60.0\nQ1[800:] = 0.0\nfor i in range(n):\n    lab.Q1(Q1[i])\n    lab.Q2(Q2[i])\n    time.sleep(1)\n    print(Q1[i],lab.T1)\n    T1.append(lab.T1)\n    T2.append(lab.T2)\nlab.close()\n# Save data file\ndata = np.vstack((tm,Q1,Q2,T1,T2)).T\nnp.savetxt('tclab_data.csv',data,delimiter=',',\\\n           header='Time,Q1,Q2,T1,T2',comments='')\n\n# Create Figure\nplt.figure(figsize=(10,7))\nax = plt.subplot(2,1,1)\nax.grid()\nplt.plot(tm/60.0,T1,'r.',label=r'$T_1$')\nplt.ylabel(r'Temp ($^oC$)')\nax = plt.subplot(2,1,2)\nax.grid()\nplt.plot(tm/60.0,Q1,'b-',label=r'$Q_1$')\nplt.ylabel(r'Heater (%)')\nplt.xlabel('Time (min)')\nplt.legend()\nplt.savefig('tclab_data.png')\nplt.show()"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "outputs": [], "source": ["import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import MinMaxScaler\nimport time\n\n# For LSTM model\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nfrom keras.layers import Dropout\nfrom keras.callbacks import EarlyStopping\nfrom keras.models import load_model\n\n# Load training data\nfile = 'http://apmonitor.com/do/uploads/Main/tclab_dyn_data3.txt'\ntrain = pd.read_csv(file)\n\n# Scale features\ns1 = MinMaxScaler(feature_range=(-1,1))\nXs = s1.fit_transform(train[['T1','Q1']])\n\n# Scale predicted value\ns2 = MinMaxScaler(feature_range=(-1,1))\nYs = s2.fit_transform(train[['T1']])\n\n# Each time step uses last 'window' to predict the next change\nwindow = 70\nX = []\nY = []\nfor i in range(window,len(Xs)):\n    X.append(Xs[i-window:i,:])\n    Y.append(Ys[i])\n\n# Reshape data to format accepted by LSTM\nX, Y = np.array(X), np.array(Y)\n\n# create and train LSTM model\n\n# Initialize LSTM model\nmodel = Sequential()\n\nmodel.add(LSTM(units=50, return_sequences=True, \\\n          input_shape=(X.shape[1],X.shape[2])))\nmodel.add(Dropout(0.2))\nmodel.add(LSTM(units=50, return_sequences=True))\nmodel.add(Dropout(0.2))\nmodel.add(LSTM(units=50))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(units=1))\nmodel.compile(optimizer = 'adam', loss = 'mean_squared_error',\\\n              metrics = ['accuracy'])\n\n# Allow for early exit \nes = EarlyStopping(monitor='loss',mode='min',verbose=1,patience=10)\n\n# Fit (and time) LSTM model\nt0 = time.time()\nhistory = model.fit(X, Y, epochs = 10, batch_size = 250, callbacks=[es], verbose=1)\nt1 = time.time()\nprint('Runtime: %.2f s' %(t1-t0))\n\n# Plot loss \nplt.figure(figsize=(8,4))\nplt.semilogy(history.history['loss'])\nplt.xlabel('epoch'); plt.ylabel('loss')\nplt.savefig('tclab_loss.png')\nmodel.save('model.h5')\n\n# Verify the fit of the model\nYp = model.predict(X)\n\n# un-scale outputs\nYu = s2.inverse_transform(Yp)\nYm = s2.inverse_transform(Y)\n\nplt.figure(figsize=(10,6))\nplt.subplot(2,1,1)\nplt.plot(train['Time'][window:],Yu,'r-',label='LSTM')\nplt.plot(train['Time'][window:],Ym,'k--',label='Measured')\nplt.ylabel('Temperature (\u00c2\u00b0C)')\nplt.legend()\nplt.subplot(2,1,2)\nplt.plot(train['Q1'],label='heater (%)')\nplt.legend()\nplt.xlabel('Time (sec)'); plt.ylabel('Heater')\nplt.savefig('tclab_fit.png')\n\n# Load model\nv = load_model('model.h5')\n# Load training data\ntest = pd.read_csv('http://apmonitor.com/pdc/uploads/Main/tclab_data4.txt')\n\nXt = test[['T1','Q1']].values\nYt = test[['T1']].values\n\nXts = s1.transform(Xt)\nYts = s2.transform(Yt)\n\nXti = []\nYti = []\nfor i in range(window,len(Xts)):\n    Xti.append(Xts[i-window:i,:])\n    Yti.append(Yts[i])\n\n# Reshape data to format accepted by LSTM\nXti, Yti = np.array(Xti), np.array(Yti)\n\n# Verify the fit of the model\nYtp = model.predict(Xti)\n\n# un-scale outputs\nYtu = s2.inverse_transform(Ytp)\nYtm = s2.inverse_transform(Yti)\n\nplt.figure(figsize=(10,6))\nplt.subplot(2,1,1)\nplt.plot(test['Time'][window:],Ytu,'r-',label='LSTM Predicted')\nplt.plot(test['Time'][window:],Ytm,'k--',label='Measured')\nplt.legend()\nplt.ylabel('Temperature (\u00c2\u00b0C)')\nplt.subplot(2,1,2)\nplt.plot(test['Time'],test['Q1'],'b-',label='Heater')\nplt.xlabel('Time (sec)'); plt.ylabel('Heater (%)')\nplt.legend()\nplt.savefig('tclab_validate.png')\n\n# Using predicted values to predict next step\nXtsq = Xts.copy()\nfor i in range(window,len(Xtsq)):\n    Xin = Xtsq[i-window:i].reshape((1, window, 2))\n    Xtsq[i][0] = v.predict(Xin)\n    Yti[i-window] = Xtsq[i][0]\n\n#Ytu = (Yti - s2.min_[0])/s2.scale_[0]\nYtu = s2.inverse_transform(Yti)\n\nplt.figure(figsize=(10,6))\nplt.subplot(2,1,1)\nplt.plot(test['Time'][window:],Ytu,'r-',label='LSTM Predicted')\nplt.plot(test['Time'][window:],Ytm,'k--',label='Measured')\nplt.legend()\nplt.ylabel('Temperature (\u00c2\u00b0C)')\nplt.subplot(2,1,2)\nplt.plot(test['Time'],test['Q1'],'b-',label='Heater')\nplt.xlabel('Time (sec)'); plt.ylabel('Heater (%)')\nplt.legend()\nplt.savefig('tclab_forecast.png')\nplt.show()"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "outputs": [], "source": ["import numpy as np\nimport matplotlib.pyplot as plt\nfrom gekko import GEKKO\nimport pandas as pd\n\nfile = 'http://apmonitor.com/do/uploads/Main/tclab_dyn_data3.txt'\ndata = pd.read_csv(file)\n\n# subset for training\nn = 3000\ntm = data['Time'][0:n].values\nQ1s = data['Q1'][0:n].values\nT1s = data['T1'][0:n].values\n\nm = GEKKO()\nm.time = tm\n\n# Parameters to Estimate\nK1 = m.FV(value=0.5,lb=0.1,ub=1.0)\ntau1 = m.FV(value=150,lb=50,ub=250)\ntau2 = m.FV(value=15,lb=10,ub=20)\nK1.STATUS = 1\ntau1.STATUS = 1\ntau2.STATUS = 1\n\n# Model Inputs\nQ1 = m.Param(value=Q1s)\nTa = m.Param(value=23.0) # degC\nT1m = m.Param(T1s)\n\n# Model Variables\nTH1 = m.Var(value=T1s[0])\nTC1 = m.Var(value=T1s)\n\n# Objective Function\nm.Minimize((T1m-TC1)**2)\n\n# Equations\nm.Equation(tau1 * TH1.dt() + (TH1-Ta) == K1*Q1)\nm.Equation(tau2 * TC1.dt()  + TC1 == TH1)\n\n# Global Options\nm.options.IMODE   = 5 # MHE\nm.options.EV_TYPE = 2 # Objective type\nm.options.NODES   = 2 # Collocation nodes\nm.options.SOLVER  = 3 # IPOPT\n\n# Predict Parameters and Temperatures\nm.solve() \n\n# Create plot\nplt.figure(figsize=(10,7))\n\nax=plt.subplot(2,1,1)\nax.grid()\nplt.plot(tm,T1s,'ro',label=r'$T_1$ measured')\nplt.plot(tm,TC1.value,'k-',label=r'$T_1$ predicted')\nplt.ylabel('Temperature (degC)')\nplt.legend(loc=2)\nax=plt.subplot(2,1,2)\nax.grid()\nplt.plot(tm,Q1s,'b-',label=r'$Q_1$')\nplt.ylabel('Heater (%)')\nplt.xlabel('Time (sec)')\nplt.legend(loc='best')\n\n# Print optimal values\nprint('K1: ' + str(K1.newval))\nprint('tau1: ' + str(tau1.newval))\nprint('tau2: ' + str(tau2.newval))\n\n# Save and show figure\nplt.savefig('tclab_2nd_order_fit.png')\n\n\n# Validation\ntm = data['Time'][n:3*n].values\nQ1s = data['Q1'][n:3*n].values\nT1s = data['T1'][n:3*n].values\n\nv = GEKKO()\nv.time = tm\n\n# Parameters to Estimate\nK1 = K1.newval\ntau1 = tau1.newval\ntau2 = tau2.newval\nQ1 = v.Param(value=Q1s)\nTa = v.Param(value=23.0) # degC\nTH1 = v.Var(value=T1s[0])\nTC1 = v.Var(value=T1s[0])\nv.Equation(tau1 * TH1.dt() + (TH1-Ta) == K1*Q1)\nv.Equation(tau2 * TC1.dt()  + TC1 == TH1)\nv.options.IMODE   = 4 # Simulate\nv.options.NODES   = 2 # Collocation nodes\nv.options.SOLVER  = 1\n\n# Predict Parameters and Temperatures\nv.solve(disp=True) \n\n# Create plot\nplt.figure(figsize=(10,7))\n\nax=plt.subplot(2,1,1)\nax.grid()\nplt.plot(tm,T1s,'ro',label=r'$T_1$ measured')\nplt.plot(tm,TC1.value,'k-',label=r'$T_1$ predicted')\nplt.ylabel('Temperature (degC)')\nplt.legend(loc=2)\nax=plt.subplot(2,1,2)\nax.grid()\nplt.plot(tm,Q1s,'b-',label=r'$Q_1$')\nplt.ylabel('Heater (%)')\nplt.xlabel('Time (sec)')\nplt.legend(loc='best')\n\n# Save and show figure\nplt.savefig('tclab_2nd_order_validate.png')\nplt.show()"], "execution_count": null, "cell_type": "code"}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}}}