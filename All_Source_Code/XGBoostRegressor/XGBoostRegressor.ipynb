{"nbformat": 4, "nbformat_minor": 2, "cells": [{"metadata": {}, "source": ["### Machine Learning for Engineers: [XGBoostRegressor](https://www.apmonitor.com/pds/index.php/Main/XGBoostRegressor)\n- [XGBoost Regressor](https://www.apmonitor.com/pds/index.php/Main/XGBoostRegressor)\n - Source Blocks: 2\n - Description: Introduction to XGBoost for Regression\n- [Course Overview](https://apmonitor.com/pds)\n- [Course Schedule](https://apmonitor.com/pds/index.php/Main/CourseSchedule)\n"], "cell_type": "markdown"}, {"metadata": {}, "outputs": [], "source": ["import xgboost as xgb\nxgbc = xgb.XGBRegressor()\nxgbc.fit(XA,yA)\nyP = xgbc.predict(XB)"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "outputs": [], "source": ["import xgboost as xgb\nfrom sklearn.datasets import make_regression\nfrom sklearn.metrics import r2_score\nfrom sklearn.model_selection import train_test_split\nimport pandas as pd\n\nX, y = make_regression(n_samples=1000, n_features=10, n_informative=8)\nXa,Xb,ya,yb = train_test_split(X, y, test_size=0.2, shuffle=True)\nxgbr = xgb.XGBRegressor()\nxgbr.fit(Xa,ya)\nyp = xgbr.predict(Xb)\nacc = r2_score(yb,yp)\nprint('R2='+str(acc))\n\n# importance_types = ['weight', 'gain', 'cover', 'total_gain', 'total_cover']\nf = xgbr.get_booster().get_score(importance_type='gain')\nt = pd.DataFrame(f.items(),columns=['Feature','Gain'])\nprint(t.sort_values('Gain',ascending=False))\n\n# create table from feature_importances_\nfi = xgbr.feature_importances_\nn = ['Feature '+str(i) for i in range(10)]\nd = pd.DataFrame({'Feature':n,'Importance':fi})\nprint(d.sort_values('Importance',ascending=False))\n\n# plot the importance by 'weight'\nxgb.plot_importance(xgbr)"], "execution_count": null, "cell_type": "code"}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}}}