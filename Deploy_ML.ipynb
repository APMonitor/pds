{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learning for Engineers: [Deploy Machine Learning](https://www.apmonitor.com/pds/index.php/Main/DeployMachineLearning)\n",
    "- [Deploy Machine Learning](https://www.apmonitor.com/pds/index.php/Main/DeployMachineLearning)\n",
    " - Description: Deploying machine learning is the process of making the machine learning solution available to produce results for people or computers to access the service remotely.\n",
    "- [Course Overview](https://apmonitor.com/pds)\n",
    "- [Course Schedule](https://apmonitor.com/pds/index.php/Main/CourseSchedule)\n",
    "\n",
    "<img align=left width=400px src='https://apmonitor.com/pds/uploads/Main/deploy_machine_learning.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pickled Python Objects\n",
    "\n",
    "Pickle files store Python objects, lists of objects, or anything else that is accessible in a Python session. The list z is dumped to the Pickle file z.pkl.\n",
    "\n",
    "<img align=left width=400 src='https://apmonitor.com/pds/uploads/Main/python_pickle.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = [1,2,3]\n",
    "import pickle\n",
    "pickle.dump(z,open('z.pkl','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `z.pkl` file can then be accessed later on that same computer or transferred to another computer and loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "y = pickle.load(open('z.pkl','rb'))\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store HDF5 Models\n",
    "\n",
    "Some Python objects, such as Keras models, cannot be stored as Pickle files. The Hierarchical Data Format, version 5 (HDF5) is a file format that is designed to store large amounts of data, model architecture, parameter weights, and other information about machine learned models. Keras supports model save and load in HDF5 format.\n",
    "\n",
    "<img width=100px align=left src='https://apmonitor.com/pds/uploads/Main/python_hdf5.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Keras model is saved with:\n",
    "\n",
    "- Keras / TensorFlow model architecture (layers, nodes, connections) and configuration (hyper-parameters such as lbfgs or adam solver, loss function, epochs, early termination criteria)\n",
    "- Weights that are adjusted during training and used for testing and validation\n",
    "\n",
    "```python\n",
    "# save model\n",
    "model.save('store.h5')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is restored into the running program by calling load_model to read the hdf5 file and rebuilt the Keras model to perform testing, validation, or deploy the machine learning solution.\n",
    "\n",
    "```python\n",
    "# load model\n",
    "from keras.models import load_model\n",
    "model = load_model('store.h5')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy Logistic Regression\n",
    "\n",
    "Pickle files can be used to store Scikit-learn machine learning models, data, scalars, or other objects needed to deploy an application on a server or other computer. A Logistic Regression model is trained on 800 data points that are randomly generated with the `make_blobs` function in `sklearn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate blobs dataset\n",
    "from sklearn.datasets import make_blobs\n",
    "features, label = make_blobs(n_samples=1000, centers=2,\\\n",
    "                             n_features=2, random_state=12)\n",
    "\n",
    "# Split into train and test subsets (20% for test)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    features, label, test_size=0.2, shuffle=False)\n",
    "\n",
    "# Train Logistic Regression model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression(solver='lbfgs')\n",
    "lr.fit(X_train,y_train)\n",
    "\n",
    "# Store model and test data\n",
    "import pickle\n",
    "store = [lr,X_test,y_test]\n",
    "pickle.dump(store,open('store.pkl','wb'))\n",
    "\n",
    "# View data\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "data = pd.DataFrame({'x1':features[:,0],\n",
    "                     'x2':features[:,1],\n",
    "                     'y':label})\n",
    "sns.pairplot(data,hue='y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model and test data are stored in a Pickle file `store.pkl`. That file can be transferred to another target computer to make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve model and test data\n",
    "import pickle\n",
    "[lr,X_test,y_test] = pickle.load(open('store.pkl','rb'))\n",
    "\n",
    "# Predict\n",
    "y_predict = lr.predict(X_test)\n",
    "\n",
    "# Generate confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "cmat = confusion_matrix(y_test,y_predict)\n",
    "sns.heatmap(cmat,annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy Number Identification\n",
    "\n",
    "The next activity is to split a program that includes training and testing into two separate programs. \n",
    "\n",
    "<img align=left width=500px src='https://apmonitor.com/pds/uploads/Main/activity.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use a pickle file to store the test data and the neural network model. Separate machine learning for number identification into a training and test program. Show that the test program can predict the second to last number in the dataset.\n",
    "\n",
    "<img align=left width=500px src='https://apmonitor.com/pds/uploads/Main/classify_numbers.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "classifier = MLPClassifier(solver='lbfgs',alpha=1e-5,max_iter=200,\\\n",
    "                    activation='relu',hidden_layer_sizes=(10,30,10),\\\n",
    "                    random_state=1, shuffle=True)\n",
    "\n",
    "# The digits dataset\n",
    "digits = datasets.load_digits()\n",
    "n_samples = len(digits.images)\n",
    "data = digits.images.reshape((n_samples, -1))\n",
    "\n",
    "# Split into train and test subsets (50% each)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data, digits.target, test_size=0.5, shuffle=False)\n",
    "\n",
    "# Learn the digits on the first half of the digits\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Test on second half of data\n",
    "n = np.random.randint(int(n_samples/2),n_samples)\n",
    "print('Predicted: ' + str(classifier.predict(digits.data[n:n+1])[0]))\n",
    "\n",
    "# Show number\n",
    "plt.imshow(digits.images[n], cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution:** The model and test data are stored in a Pickle file `store.pkl`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# The digits dataset\n",
    "digits = datasets.load_digits()\n",
    "n_samples = len(digits.images)\n",
    "data = digits.images.reshape((n_samples, -1))\n",
    "\n",
    "# Split into train and test subsets (50% each)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data, digits.target, test_size=0.5, shuffle=False)\n",
    "\n",
    "# Learn the digits on the first half of the digits\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Store model and test data\n",
    "import pickle\n",
    "store = [classifier,digits]\n",
    "pickle.dump(store,open('store.pkl','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution:** The pickle file `store.pkl` file can be transferred to another target computer to make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve model and test data\n",
    "import pickle\n",
    "[classifier,digits] = pickle.load(open('store.pkl','rb'))\n",
    "\n",
    "# Test on second to last number\n",
    "print('Predicted: ' + str(classifier.predict(digits.data[-2:-1])[0]))\n",
    "\n",
    "# Show number\n",
    "plt.imshow(digits.images[-2], cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy Gekko MPC\n",
    "\n",
    "[Model Predictive Control](https://apmonitor.com/do/index.php/Main/AdvancedTemperatureControl) is an advanced control method to regulate multivariate dynamic systems.\n",
    "\n",
    "<img align=left width=400px src='https://apmonitor.com/do/uploads/Main/mpc_mimo_tclab.gif'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first time through, the application is created and stored as `m.pkl`. When the `m.pkl` file exists, the pickle file is reloaded instead of creating a new application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import exists\n",
    "import pickle\n",
    "import numpy as np\n",
    "from gekko import GEKKO\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if exists('m.pkl'):\n",
    "    # load model from subsequent call\n",
    "    m = pickle.load(open('m.pkl','rb'))\n",
    "    m.solve(disp=False)\n",
    "else:\n",
    "    # define model the first time\n",
    "    m = GEKKO()\n",
    "    m.time = np.linspace(0,20,41)\n",
    "\n",
    "    m.p = m.MV(value=0, lb=0, ub=1)\n",
    "    m.v = m.CV(value=0)\n",
    "    m.Equation(5*m.v.dt() == -m.v + 10*m.p)\n",
    "    m.options.IMODE = 6\n",
    "    m.p.STATUS = 1; m.p.DCOST = 1e-3\n",
    "    m.v.STATUS = 1; m.v.SP = 40; m.v.TAU = 5\n",
    "    m.options.CV_TYPE = 2\n",
    "    m.solve(disp=False)\n",
    "pickle.dump(m,open('m.pkl','wb'))\n",
    "\n",
    "plt.figure()\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(m.time,m.p.value,'b-',lw=2)\n",
    "plt.ylabel('gas')\n",
    "plt.subplot(2,1,2)\n",
    "plt.plot(m.time,m.v.value,'r--',lw=2)\n",
    "plt.ylabel('velocity')\n",
    "plt.xlabel('time')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
