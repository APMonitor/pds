{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-21T14:51:10.384496Z",
     "start_time": "2021-01-21T14:51:00.608649Z"
    }
   },
   "outputs": [],
   "source": [
    "from numpy.random import rand\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from sklearn import linear_model\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "import tensorflow as tf\n",
    "from scipy import stats\n",
    "import torch\n",
    "from gekko import GEKKO\n",
    "from torch.autograd import Variable\n",
    "from keras.models import Sequential\n",
    "from keras.layers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-21T14:51:10.400406Z",
     "start_time": "2021-01-21T14:51:10.386420Z"
    }
   },
   "outputs": [],
   "source": [
    "test_time = 20.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-21T14:51:10.415426Z",
     "start_time": "2021-01-21T14:51:10.402406Z"
    }
   },
   "outputs": [],
   "source": [
    "w = rand()\n",
    "b = rand()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-21T14:51:10.431404Z",
     "start_time": "2021-01-21T14:51:10.419406Z"
    }
   },
   "outputs": [],
   "source": [
    "cols = ['scipy','statsmodel','numpy','sklearn','nn','keras nn','gekko','keras','tf','pytorch']\n",
    "n = 100\n",
    "index = []\n",
    "for i in range(25):\n",
    "    index.append(n)\n",
    "    n *= 2\n",
    "    \n",
    "results = pd.DataFrame(columns=cols,index = index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-21T14:52:23.404571Z",
     "start_time": "2021-01-21T14:51:10.433414Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 0.05449867248535156\n",
      "200 0.0009975433349609375\n",
      "400 0.0\n",
      "800 0.0009970664978027344\n",
      "1600 0.001010894775390625\n",
      "3200 0.0\n",
      "6400 0.001995086669921875\n",
      "12800 0.0029938220977783203\n",
      "25600 0.003023862838745117\n",
      "51200 0.008975744247436523\n",
      "102400 0.012932538986206055\n",
      "204800 0.035903215408325195\n",
      "409600 0.07878923416137695\n",
      "819200 0.12167549133300781\n",
      "1638400 0.2622988224029541\n",
      "3276800 0.48171377182006836\n",
      "6553600 0.9982964992523193\n",
      "13107200 1.9228532314300537\n",
      "26214400 3.8522789478302\n",
      "52428800 16.984108209609985\n"
     ]
    }
   ],
   "source": [
    "# Statsmodels OLS\n",
    "n = 100\n",
    "start = time.time()\n",
    "while time.time() <= start + test_time:\n",
    "    x = np.linspace(0,100,n)\n",
    "    y = w * x + b\n",
    "    \n",
    "    # Add Gaussian noise\n",
    "    noise = np.random.normal(0,1.0,n); y += noise\n",
    "    \n",
    "    # scipy\n",
    "    xc = sm.add_constant(x)\n",
    "    t0 = time.time()\n",
    "    model = sm.OLS(y,xc).fit()\n",
    "    predictions = model.predict(xc)\n",
    "    t1 = time.time()\n",
    "    print(n,t1-t0)\n",
    "    results['statsmodel'].loc[n] = t1 - t0\n",
    "    \n",
    "    n = n * 2 # Double number of data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-21T14:53:25.406977Z",
     "start_time": "2021-01-21T14:52:23.428572Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 0.03291201591491699\n",
      "200 0.0019948482513427734\n",
      "400 0.0009968280792236328\n",
      "800 0.0009975433349609375\n",
      "1600 0.0009975433349609375\n",
      "3200 0.0009970664978027344\n",
      "6400 0.0019948482513427734\n",
      "12800 0.0029916763305664062\n",
      "25600 0.0029938220977783203\n",
      "51200 0.0069811344146728516\n",
      "102400 0.011969566345214844\n",
      "204800 0.02393651008605957\n",
      "409600 0.04986715316772461\n",
      "819200 0.08776521682739258\n",
      "1638400 0.21342730522155762\n",
      "3276800 0.3311135768890381\n",
      "6553600 0.7051131725311279\n",
      "13107200 1.2586326599121094\n",
      "26214400 2.405526876449585\n",
      "52428800 9.97437572479248\n"
     ]
    }
   ],
   "source": [
    "# Numpy\n",
    "n = 100\n",
    "start = time.time()\n",
    "while time.time() <= start + test_time:\n",
    "    x = np.linspace(0,100,n)\n",
    "    y = w * x + b\n",
    "    \n",
    "    # Add Gaussian noise\n",
    "    noise = np.random.normal(0,1.0,n)\n",
    "    y += noise\n",
    "    \n",
    "    # numpy\n",
    "    t0 = time.time()\n",
    "    np.polyfit(x,y,1)\n",
    "    t1 = time.time()\n",
    "    print(n,t1-t0)\n",
    "    results['numpy'].loc[n] = t1 - t0\n",
    "    \n",
    "    n = n * 2 # Double number of data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-21T14:54:54.452564Z",
     "start_time": "2021-01-21T14:53:25.417972Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 0.0857701301574707\n",
      "200 0.001993417739868164\n",
      "400 0.0019943714141845703\n",
      "800 0.0019958019256591797\n",
      "1600 0.000997781753540039\n",
      "3200 0.000997781753540039\n",
      "6400 0.001993417739868164\n",
      "12800 0.001995563507080078\n",
      "25600 0.002996206283569336\n",
      "51200 0.00498652458190918\n",
      "102400 0.0109710693359375\n",
      "204800 0.013962268829345703\n",
      "409600 0.028921127319335938\n",
      "819200 0.05186009407043457\n",
      "1638400 0.10671472549438477\n",
      "3276800 0.19148778915405273\n",
      "6553600 0.38496994972229004\n",
      "13107200 0.8377599716186523\n",
      "26214400 1.5927367210388184\n",
      "52428800 2.8324201107025146\n",
      "104857600 17.778105974197388\n"
     ]
    }
   ],
   "source": [
    "# sklearn\n",
    "n = 100\n",
    "start = time.time()\n",
    "while time.time() <= start + test_time:\n",
    "    x = np.linspace(0,100,n)\n",
    "    y = w * x + b\n",
    "    \n",
    "    # Add Gaussian noise\n",
    "    noise = np.random.normal(0,1.0,n)\n",
    "    y += noise\n",
    "    \n",
    "    # numpy\n",
    "    t0 = time.time()\n",
    "    lm = linear_model.LinearRegression()\n",
    "    lm.fit(x.reshape((n,1)),y)\n",
    "    t1 = time.time()\n",
    "    print(n,t1-t0)\n",
    "    results['sklearn'].loc[n] = t1 - t0\n",
    "    \n",
    "    n = n * 2 # Double number of data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-21T14:55:28.823537Z",
     "start_time": "2021-01-21T14:54:54.493923Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 1.2606847286224365\n",
      "200 0.662193775177002\n",
      "400 1.8112378120422363\n",
      "800 0.8757038116455078\n",
      "1600 1.7268800735473633\n",
      "3200 7.130922079086304\n",
      "6400 2.7506439685821533\n",
      "12800 12.814718008041382\n"
     ]
    }
   ],
   "source": [
    "# Scikit-learn neural network\n",
    "n = 100\n",
    "start = time.time()\n",
    "while time.time() <= start + test_time:\n",
    "    x = np.linspace(0,100,n)\n",
    "    y = w * x + b\n",
    "    \n",
    "    # Add Gaussian noise\n",
    "    noise = np.random.normal(0,1.0,n)\n",
    "    y += noise\n",
    "    \n",
    "    # Neural network\n",
    "    t0 = time.time()\n",
    "    nn = MLPRegressor(hidden_layer_sizes=((10,10)),activation='tanh',\\\n",
    "                      solver='lbfgs',max_iter=5000)\n",
    "    nn.fit(x.reshape((n,1)),y)\n",
    "    t1 = time.time()\n",
    "    print(n,t1-t0)\n",
    "    results['nn'].loc[n] = t1 - t0\n",
    "    \n",
    "    n = n * 2 # Double number of data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-21T14:56:41.297354Z",
     "start_time": "2021-01-21T14:55:28.826502Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 2.0555145740509033\n",
      "400 1.3630356788635254\n",
      "1600 1.8589675426483154\n",
      "6400 1.2915656566619873\n",
      "25600 1.7812342643737793\n",
      "102400 3.6777689456939697\n",
      "409600 15.184376955032349\n"
     ]
    }
   ],
   "source": [
    "# Keras nn\n",
    "n_inputs = 1\n",
    "nodes = 10\n",
    "skip = 2\n",
    "\n",
    "# create neural network model\n",
    "model = Sequential()\n",
    "model.add(Dense(n_inputs, input_dim=n_inputs, activation='linear'))\n",
    "model.add(Dense(nodes, activation='linear'))\n",
    "model.add(Dense(nodes, activation='tanh'))\n",
    "model.add(Dense(nodes, activation='tanh'))\n",
    "model.add(Dense(nodes, activation='linear'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"adam\")\n",
    "\n",
    "n = 100\n",
    "start = time.time()\n",
    "while time.time() <= start + test_time:\n",
    "    x = np.linspace(0,100,n)\n",
    "    y = w * x + b\n",
    "    \n",
    "    # Add Gaussian noise\n",
    "    noise = np.random.normal(0,1.0,n)\n",
    "    y += noise\n",
    "    \n",
    "    # Keras \n",
    "    t0 = time.time()\n",
    "    model.fit(x,y,epochs=100,batch_size=int(n/10),verbose=0,shuffle=True)\n",
    "    t1 = time.time()\n",
    "    print(n,t1-t0)\n",
    "    results['keras nn'].loc[n] = t1 - t0\n",
    "    \n",
    "    n = n * 2 * skip # Quadruple number of data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-21T14:58:34.465073Z",
     "start_time": "2021-01-21T14:56:41.300356Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 1.0112953186035156\n",
      "400 1.0672059059143066\n",
      "1600 1.1352770328521729\n",
      "6400 1.024613380432129\n",
      "25600 1.2698099613189697\n",
      "102400 1.7482900619506836\n",
      "409600 3.5664334297180176\n",
      "1638400 21.902881860733032\n"
     ]
    }
   ],
   "source": [
    "# Keras linear regression\n",
    "model = Sequential()\n",
    "model.add(Dense(1, input_dim=1, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "n = 100\n",
    "start = time.time()\n",
    "while time.time() <= start + test_time:\n",
    "    x = np.linspace(0,100,n)\n",
    "    y = w * x + b\n",
    "    \n",
    "    # Add Gaussian noise\n",
    "    noise = np.random.normal(0,1.0,n)\n",
    "    y += noise\n",
    "    \n",
    "    # Keras \n",
    "    t0 = time.time()\n",
    "    model.fit(x,y,epochs=100,batch_size=int(n/10),verbose=0,shuffle=True)\n",
    "    t1 = time.time()\n",
    "    print(n,t1-t0)\n",
    "    results['keras'].loc[n] = t1 - t0\n",
    "    \n",
    "    n = n * 2 * skip # Quadruple number of data points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Keras, TF, change input parameters such as epochs, batch size, nodes, number of layers, etc, to see how it affects time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-21T14:59:54.620621Z",
     "start_time": "2021-01-21T14:58:34.468073Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 0.23536896705627441\n",
      "400 0.28923797607421875\n",
      "1600 0.4348611831665039\n",
      "6400 0.2254025936126709\n",
      "25600 0.23637771606445312\n",
      "102400 0.628319263458252\n",
      "409600 1.3364105224609375\n"
     ]
    }
   ],
   "source": [
    "# Tensorflow\n",
    "learning_rate = 0.01\n",
    "epochs = 100\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "# Weight and Bias variables\n",
    "m = tf.Variable(tf.zeros(1), name='weight')\n",
    "a = tf.Variable(tf.zeros(1), name='bias')\n",
    "\n",
    "def predict(x):\n",
    "    return x * m + a\n",
    "\n",
    "def mse(y_true, y_pred):\n",
    "    return tf.losses.mean_squared_error(y_true,y_pred)\n",
    "\n",
    "def fit_TF(x,y):\n",
    "    for epoch in range(1, epochs + 1):\n",
    "    # Begin GradientTape and optimise\n",
    "        with tf.GradientTape() as g:\n",
    "            pred = predict(x)\n",
    "            loss = mse(y, pred)\n",
    "\n",
    "        # Compute dw, db\n",
    "        gradients = g.gradient(loss, [m,a])\n",
    "\n",
    "        # Update w and b\n",
    "        optimizer.apply_gradients(zip(gradients, [m,a]))\n",
    "    \n",
    "    return (m.numpy(),a.numpy())\n",
    "\n",
    "# SGD Optimizer\n",
    "optimizer = tf.optimizers.SGD(learning_rate=learning_rate)\n",
    "\n",
    "n = 100\n",
    "start = time.time()\n",
    "\n",
    "while time.time() <= start + test_time:\n",
    "    x = np.linspace(0,100,n)\n",
    "    y = w * x + b\n",
    "    \n",
    "    # Add Gaussian noise\n",
    "    noise = np.random.normal(0,1.0,n)\n",
    "    y += noise\n",
    "    \n",
    "    # TF\n",
    "    t0 = time.time()\n",
    "    fit_TF(x,y)\n",
    "    t1 = time.time()\n",
    "    print(n,t1-t0)\n",
    "    results['tf'].loc[n] = t1 - t0\n",
    "    \n",
    "    n = n * 2 * skip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-21T15:01:25.735846Z",
     "start_time": "2021-01-21T14:59:54.622623Z"
    }
   },
   "outputs": [],
   "source": [
    "# Scipy\n",
    "n = 100\n",
    "start = time.time()\n",
    "while time.time() <= start + test_time:\n",
    "    x = np.linspace(0,100,n)\n",
    "    y = w * x + b\n",
    "    \n",
    "    # Add Gaussian noise\n",
    "    noise = np.random.normal(0,1.0,n)\n",
    "    y += noise\n",
    "    \n",
    "    # numpy\n",
    "    t0 = time.time()\n",
    "    stats.linregress(x,y)\n",
    "    t1 = time.time()\n",
    "    print(n,t1-t0)\n",
    "    results['scipy'].loc[n] = t1 - t0\n",
    "    \n",
    "    n = n * 2 # Double number of data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gekko\n",
    "n = 100\n",
    "start = time.time()\n",
    "while time.time() <= start + test_time*3:\n",
    "    x = np.linspace(0,100,n)\n",
    "    y = w * x + b\n",
    "    \n",
    "    # Add Gaussian noise\n",
    "    noise = np.random.normal(0,1.0,n); y += noise\n",
    "    \n",
    "    # gekko\n",
    "    m = GEKKO(remote=True,server='http://apmonitor.com')\n",
    "    yg = m.Var(y); xg = m.Param(x); ym = m.Param(y)\n",
    "    wg = m.FV(); wg.STATUS = 1; bg = m.FV(); bg.STATUS = 1\n",
    "    m.Equation(yg==wg*xg+bg); m.options.IMODE=2\n",
    "    m.Minimize((yg-ym)**2)\n",
    "    \n",
    "    t0 = time.time()\n",
    "    try:\n",
    "        m.solve(disp=False)\n",
    "        t1 = time.time()\n",
    "        print(n,t1-t0)\n",
    "        results['gekko'].loc[n] = t1 - t0\n",
    "        # get solve time from remote server\n",
    "        results['gekko'].loc[n] = m.options.SOLVETIME\n",
    "    except:\n",
    "        print('Server not available or time-out')\n",
    "    \n",
    "    n = n * 2 # Double number of data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-21T15:02:35.577154Z",
     "start_time": "2021-01-21T15:01:25.782722Z"
    }
   },
   "outputs": [],
   "source": [
    "# Pytorch\n",
    "class linearRegression(torch.nn.Module):\n",
    "    def __init__(self, inputSize, outputSize):\n",
    "        super(linearRegression, self).__init__()\n",
    "        self.linear = torch.nn.Linear(inputSize, outputSize)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        return out\n",
    "    \n",
    "inputDim = 1        # takes variable 'x' \n",
    "outputDim = 1       # takes variable 'y'\n",
    "learningRate = 0.01 \n",
    "epochs = 100\n",
    "\n",
    "model = linearRegression(inputDim, outputDim)\n",
    "criterion = torch.nn.MSELoss() \n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learningRate)\n",
    "\n",
    "def fit_pytorch(x,y):\n",
    "    x = x.reshape(len(x),1)\n",
    "    y = y.reshape(len(y),1)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Converting inputs and labels to Variable\n",
    "        inputs = Variable(torch.from_numpy(x).float())\n",
    "        labels = Variable(torch.from_numpy(y).float())\n",
    "\n",
    "        # Clear gradient buffers because we don't want any gradient\n",
    "        #  from previous epoch to carry forward, dont want to \n",
    "        #  cummulate gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # get output from the model, given the inputs\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # get loss for the predicted output\n",
    "        loss = criterion(outputs, labels)\n",
    "        print(loss)\n",
    "        # get gradients w.r.t to parameters\n",
    "        loss.backward()\n",
    "\n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "n = 100\n",
    "start = time.time()\n",
    "\n",
    "while time.time() <= start + test_time:\n",
    "    x = np.linspace(0,100,n)\n",
    "    w = 0; b = 0\n",
    "    y = w * x + b\n",
    "    \n",
    "    # Add Gaussian noise\n",
    "    noise = np.random.normal(0,1.0,n)\n",
    "    y += noise\n",
    "    \n",
    "    # TF\n",
    "    t0 = time.time()\n",
    "    fit_pytorch(x,y)\n",
    "    t1 = time.time()\n",
    "    print(n,t1-t0)\n",
    "    results['pytorch'].loc[n] = t1 - t0\n",
    "    \n",
    "    n = n * 2 * skip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-21T15:02:36.684660Z",
     "start_time": "2021-01-21T15:02:35.580154Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(results['keras'][::skip],'r-',label='keras linear')\n",
    "plt.plot(results['gekko'],'k:',lw=2,label='gekko')\n",
    "plt.plot(results['tf'][::skip],'g-',label='tensorflow linear')\n",
    "plt.plot(results['pytorch'][::skip],'b.-',label='pytorch linear')\n",
    "plt.plot(results['statsmodel'],'r--',lw=2,label='statsmodel ols')\n",
    "plt.plot(results['numpy'],'k-',lw=2,label='numpy polyfit')\n",
    "plt.plot(results['sklearn'],'g:',lw=2,label='sklearn linear')\n",
    "plt.plot(results['scipy'],'b-',lw=2,label='scipy linregress')\n",
    "plt.xscale('log')\n",
    "plt.ylabel('Train Time (sec)')\n",
    "plt.legend()\n",
    "xlim = plt.gca().get_xlim()\n",
    "plt.ylim([0,test_time])\n",
    "plt.grid()\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "plt.plot(results['nn'],'b-',label='sklearn nn')\n",
    "plt.plot(results['keras nn'][::skip],'r:',label='keras nn')\n",
    "plt.xscale('log')\n",
    "plt.ylabel('Train Time (sec)')\n",
    "plt.xlabel('Problem Size (samples)')\n",
    "plt.legend()\n",
    "plt.xlim(xlim)\n",
    "plt.ylim([0,test_time])\n",
    "plt.grid()\n",
    "plt.savefig('timing_results.png',dpi=600)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
