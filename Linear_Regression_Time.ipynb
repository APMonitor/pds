{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-21T14:51:10.384496Z",
     "start_time": "2021-01-21T14:51:00.608649Z"
    }
   },
   "outputs": [],
   "source": [
    "from numpy.random import rand\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from sklearn import linear_model\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "import tensorflow as tf\n",
    "from scipy import stats\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from keras.models import Sequential\n",
    "from keras.layers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-21T14:51:10.400406Z",
     "start_time": "2021-01-21T14:51:10.386420Z"
    }
   },
   "outputs": [],
   "source": [
    "test_time = 20.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-21T14:51:10.415426Z",
     "start_time": "2021-01-21T14:51:10.402406Z"
    }
   },
   "outputs": [],
   "source": [
    "w = rand()\n",
    "b = rand()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-21T14:51:10.431404Z",
     "start_time": "2021-01-21T14:51:10.419406Z"
    }
   },
   "outputs": [],
   "source": [
    "cols = ['scipy','statsmodel','numpy','sklearn','nn','keras nn','keras','tf','pytorch']\n",
    "n = 100\n",
    "index = []\n",
    "for i in range(25):\n",
    "    index.append(n)\n",
    "    n *= 2\n",
    "    \n",
    "results = pd.DataFrame(columns=cols,index = index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-21T14:52:23.404571Z",
     "start_time": "2021-01-21T14:51:10.433414Z"
    }
   },
   "outputs": [],
   "source": [
    "# Statsmodels OLS\n",
    "n = 100\n",
    "start = time.time()\n",
    "while time.time() <= start + test_time:\n",
    "    x = np.linspace(0,100,n)\n",
    "    y = w * x + b\n",
    "    \n",
    "    # Add Gaussian noise\n",
    "    noise = np.random.normal(0,1.0,n); y += noise\n",
    "    \n",
    "    # scipy\n",
    "    xc = sm.add_constant(x)\n",
    "    t0 = time.time()\n",
    "    model = sm.OLS(y,xc).fit()\n",
    "    predictions = model.predict(xc)\n",
    "    t1 = time.time()\n",
    "    print(n,t1-t0)\n",
    "    results['statsmodel'].loc[n] = t1 - t0\n",
    "    \n",
    "    n = n * 2 # Double number of data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-21T14:53:25.406977Z",
     "start_time": "2021-01-21T14:52:23.428572Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Numpy\n",
    "n = 100\n",
    "start = time.time()\n",
    "while time.time() <= start + test_time:\n",
    "    x = np.linspace(0,100,n)\n",
    "    y = w * x + b\n",
    "    \n",
    "    # Add Gaussian noise\n",
    "    noise = np.random.normal(0,1.0,n)\n",
    "    y += noise\n",
    "    \n",
    "    # numpy\n",
    "    t0 = time.time()\n",
    "    np.polyfit(x,y,1)\n",
    "    t1 = time.time()\n",
    "    print(n,t1-t0)\n",
    "    results['numpy'].loc[n] = t1 - t0\n",
    "    \n",
    "    n = n * 2 # Double number of data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-21T14:54:54.452564Z",
     "start_time": "2021-01-21T14:53:25.417972Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# sklearn\n",
    "n = 100\n",
    "start = time.time()\n",
    "while time.time() <= start + test_time:\n",
    "    x = np.linspace(0,100,n)\n",
    "    y = w * x + b\n",
    "    \n",
    "    # Add Gaussian noise\n",
    "    noise = np.random.normal(0,1.0,n)\n",
    "    y += noise\n",
    "    \n",
    "    # numpy\n",
    "    t0 = time.time()\n",
    "    lm = linear_model.LinearRegression()\n",
    "    lm.fit(x.reshape((n,1)),y)\n",
    "    t1 = time.time()\n",
    "    print(n,t1-t0)\n",
    "    results['sklearn'].loc[n] = t1 - t0\n",
    "    \n",
    "    n = n * 2 # Double number of data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-21T14:55:28.823537Z",
     "start_time": "2021-01-21T14:54:54.493923Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Scikit-learn neural network\n",
    "n = 100\n",
    "start = time.time()\n",
    "while time.time() <= start + test_time:\n",
    "    x = np.linspace(0,100,n)\n",
    "    y = w * x + b\n",
    "    \n",
    "    # Add Gaussian noise\n",
    "    noise = np.random.normal(0,1.0,n)\n",
    "    y += noise\n",
    "    \n",
    "    # Neural network\n",
    "    t0 = time.time()\n",
    "    nn = MLPRegressor(hidden_layer_sizes=((10,10)),activation='tanh',\\\n",
    "                      solver='lbfgs',max_iter=5000)\n",
    "    nn.fit(x.reshape((n,1)),y)\n",
    "    t1 = time.time()\n",
    "    print(n,t1-t0)\n",
    "    results['nn'].loc[n] = t1 - t0\n",
    "    \n",
    "    n = n * 2 # Double number of data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-21T14:56:41.297354Z",
     "start_time": "2021-01-21T14:55:28.826502Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Keras nn\n",
    "n_inputs = 1\n",
    "nodes = 10\n",
    "skip = 2\n",
    "\n",
    "# create neural network model\n",
    "model = Sequential()\n",
    "model.add(Dense(n_inputs, input_dim=n_inputs, activation='linear'))\n",
    "model.add(Dense(nodes, activation='linear'))\n",
    "model.add(Dense(nodes, activation='tanh'))\n",
    "model.add(Dense(nodes, activation='tanh'))\n",
    "model.add(Dense(nodes, activation='linear'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"adam\")\n",
    "\n",
    "n = 100\n",
    "start = time.time()\n",
    "while time.time() <= start + test_time:\n",
    "    x = np.linspace(0,100,n)\n",
    "    y = w * x + b\n",
    "    \n",
    "    # Add Gaussian noise\n",
    "    noise = np.random.normal(0,1.0,n)\n",
    "    y += noise\n",
    "    \n",
    "    # Keras \n",
    "    t0 = time.time()\n",
    "    model.fit(x,y,epochs=100,batch_size=int(n/10),verbose=0,shuffle=True)\n",
    "    t1 = time.time()\n",
    "    print(n,t1-t0)\n",
    "    results['keras nn'].loc[n] = t1 - t0\n",
    "    \n",
    "    n = n * 2 * skip # Quadruple number of data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-21T14:58:34.465073Z",
     "start_time": "2021-01-21T14:56:41.300356Z"
    }
   },
   "outputs": [],
   "source": [
    "# Keras linear regression\n",
    "model = Sequential()\n",
    "model.add(Dense(1, input_dim=1, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "n = 100\n",
    "start = time.time()\n",
    "while time.time() <= start + test_time:\n",
    "    x = np.linspace(0,100,n)\n",
    "    y = w * x + b\n",
    "    \n",
    "    # Add Gaussian noise\n",
    "    noise = np.random.normal(0,1.0,n)\n",
    "    y += noise\n",
    "    \n",
    "    # Keras \n",
    "    t0 = time.time()\n",
    "    model.fit(x,y,epochs=100,batch_size=int(n/10),verbose=0,shuffle=True)\n",
    "    t1 = time.time()\n",
    "    print(n,t1-t0)\n",
    "    results['keras'].loc[n] = t1 - t0\n",
    "    \n",
    "    n = n * 2 * skip # Quadruple number of data points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Keras, TF, change input parameters such as epochs, batch size, nodes, number of layers, etc, to see how it affects time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-21T14:59:54.620621Z",
     "start_time": "2021-01-21T14:58:34.468073Z"
    }
   },
   "outputs": [],
   "source": [
    "# Tensorflow\n",
    "learning_rate = 0.01\n",
    "epochs = 100\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "# Weight and Bias variables\n",
    "m = tf.Variable(tf.zeros(1), name='weight')\n",
    "a = tf.Variable(tf.zeros(1), name='bias')\n",
    "\n",
    "def predict(x):\n",
    "    return x * m + a\n",
    "\n",
    "def mse(y_true, y_pred):\n",
    "    return tf.losses.mean_squared_error(y_true,y_pred)\n",
    "\n",
    "def fit_TF(x,y):\n",
    "    for epoch in range(1, epochs + 1):\n",
    "    # Begin GradientTape and optimise\n",
    "        with tf.GradientTape() as g:\n",
    "            pred = predict(x)\n",
    "            loss = mse(y, pred)\n",
    "\n",
    "        # Compute dw, db\n",
    "        gradients = g.gradient(loss, [m,a])\n",
    "\n",
    "        # Update w and b\n",
    "        optimizer.apply_gradients(zip(gradients, [m,a]))\n",
    "    \n",
    "    return (m.numpy(),a.numpy())\n",
    "\n",
    "# SGD Optimizer\n",
    "optimizer = tf.optimizers.SGD(learning_rate=learning_rate)\n",
    "\n",
    "n = 100\n",
    "start = time.time()\n",
    "\n",
    "while time.time() <= start + test_time:\n",
    "    x = np.linspace(0,100,n)\n",
    "    y = w * x + b\n",
    "    \n",
    "    # Add Gaussian noise\n",
    "    noise = np.random.normal(0,1.0,n)\n",
    "    y += noise\n",
    "    \n",
    "    # TF\n",
    "    t0 = time.time()\n",
    "    fit_TF(x,y)\n",
    "    t1 = time.time()\n",
    "    print(n,t1-t0)\n",
    "    results['tf'].loc[n] = t1 - t0\n",
    "    \n",
    "    n = n * 2 * skip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-21T15:01:25.735846Z",
     "start_time": "2021-01-21T14:59:54.622623Z"
    }
   },
   "outputs": [],
   "source": [
    "# Scipy\n",
    "n = 100\n",
    "start = time.time()\n",
    "while time.time() <= start + test_time:\n",
    "    x = np.linspace(0,100,n)\n",
    "    y = w * x + b\n",
    "    \n",
    "    # Add Gaussian noise\n",
    "    noise = np.random.normal(0,1.0,n)\n",
    "    y += noise\n",
    "    \n",
    "    # numpy\n",
    "    t0 = time.time()\n",
    "    stats.linregress(x,y)\n",
    "    t1 = time.time()\n",
    "    print(n,t1-t0)\n",
    "    results['scipy'].loc[n] = t1 - t0\n",
    "    \n",
    "    n = n * 2 # Double number of data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-21T15:02:35.577154Z",
     "start_time": "2021-01-21T15:01:25.782722Z"
    }
   },
   "outputs": [],
   "source": [
    "# Pytorch\n",
    "class linearRegression(torch.nn.Module):\n",
    "    def __init__(self, inputSize, outputSize):\n",
    "        super(linearRegression, self).__init__()\n",
    "        self.linear = torch.nn.Linear(inputSize, outputSize)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        return out\n",
    "    \n",
    "inputDim = 1        # takes variable 'x' \n",
    "outputDim = 1       # takes variable 'y'\n",
    "learningRate = 0.01 \n",
    "epochs = 100\n",
    "\n",
    "model = linearRegression(inputDim, outputDim)\n",
    "criterion = torch.nn.MSELoss() \n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learningRate)\n",
    "\n",
    "def fit_pytorch(x,y):\n",
    "    x = x.reshape(len(x),1)\n",
    "    y = y.reshape(len(y),1)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Converting inputs and labels to Variable\n",
    "        inputs = Variable(torch.from_numpy(x).float())\n",
    "        labels = Variable(torch.from_numpy(y).float())\n",
    "\n",
    "        # Clear gradient buffers because we don't want any gradient\n",
    "        #  from previous epoch to carry forward, dont want to \n",
    "        #  cummulate gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # get output from the model, given the inputs\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # get loss for the predicted output\n",
    "        loss = criterion(outputs, labels)\n",
    "        print(loss)\n",
    "        # get gradients w.r.t to parameters\n",
    "        loss.backward()\n",
    "\n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "n = 100\n",
    "start = time.time()\n",
    "\n",
    "while time.time() <= start + test_time:\n",
    "    x = np.linspace(0,100,n)\n",
    "    y = w * x + b\n",
    "    \n",
    "    # Add Gaussian noise\n",
    "    noise = np.random.normal(0,1.0,n)\n",
    "    y += noise\n",
    "    \n",
    "    # TF\n",
    "    t0 = time.time()\n",
    "    fit_pytorch(x,y)\n",
    "    t1 = time.time()\n",
    "    print(n,t1-t0)\n",
    "    results['pytorch'].loc[n] = t1 - t0\n",
    "    \n",
    "    n = n * 2 * skip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-21T15:02:36.684660Z",
     "start_time": "2021-01-21T15:02:35.580154Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(results['keras'][::skip],'r-',label='keras linear')\n",
    "plt.plot(results['tf'][::skip],'g-',label='tensorflow linear')\n",
    "plt.plot(results['pytorch'][::skip],'b.-',label='pytorch linear')\n",
    "plt.plot(results['statsmodel'],'r--',lw=2,label='statsmodel ols')\n",
    "plt.plot(results['numpy'],'k-',lw=2,label='numpy polyfit')\n",
    "plt.plot(results['sklearn'],'g:',lw=2,label='sklearn linear')\n",
    "plt.plot(results['scipy'],'b-',lw=2,label='scipy linregress')\n",
    "plt.xscale('log')\n",
    "plt.ylabel('Train Time (sec)')\n",
    "plt.legend()\n",
    "xlim = plt.gca().get_xlim()\n",
    "plt.ylim([0,test_time])\n",
    "plt.grid()\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "plt.plot(results['nn'],'b-',label='sklearn nn')\n",
    "plt.plot(results['keras nn'][::skip],'r:',label='keras nn')\n",
    "plt.xscale('log')\n",
    "plt.ylabel('Train Time (sec)')\n",
    "plt.xlabel('Problem Size (samples)')\n",
    "plt.legend()\n",
    "plt.xlim(xlim)\n",
    "plt.ylim([0,test_time])\n",
    "plt.grid()\n",
    "plt.savefig('timing_results.png',dpi=600)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
