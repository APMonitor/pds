{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression with TensorFlow and PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-22T21:21:27.870475Z",
     "start_time": "2021-01-22T21:21:25.010772Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-22T21:21:28.265537Z",
     "start_time": "2021-01-22T21:21:27.873474Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('mfr_data.pkl', 'rb') as handle:\n",
    "    info = pickle.load(handle)\n",
    "data,test,train,ds,s = info\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-22T21:21:28.281536Z",
     "start_time": "2021-01-22T21:21:28.268537Z"
    }
   },
   "outputs": [],
   "source": [
    "# Split data/labels\n",
    "data_X = np.array(data['H2R'])\n",
    "data_Y = np.array(data['lnMFR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-14T15:09:44.372119Z",
     "start_time": "2021-01-14T15:09:44.259015Z"
    }
   },
   "source": [
    "![exercise](https://apmonitor.com/che263/uploads/Begin_Python/exercise.png)\n",
    "\n",
    "### Tensorflow Linear Regression\n",
    "\n",
    "TensorFlow is known for Deep Learning. This tutorial shows how to use TensorFlow for a simple linear regression. There are better packages for linear regression. Also, Keras is an interface to TensorFlow that simplifies the model building, regression solution, and deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-22T21:21:30.370753Z",
     "start_time": "2021-01-22T21:21:30.365767Z"
    }
   },
   "outputs": [],
   "source": [
    "display_step = 100\n",
    "learning_rate = 0.01\n",
    "epochs = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$y=wx+b$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-22T21:21:34.895962Z",
     "start_time": "2021-01-22T21:21:34.846270Z"
    }
   },
   "outputs": [],
   "source": [
    "# Weight and Bias\n",
    "w = tf.Variable(tf.zeros(1), name='weight')\n",
    "b = tf.Variable(tf.zeros(1), name='bias')\n",
    "\n",
    "def predict(x):\n",
    "    return x * w + b\n",
    "\n",
    "def mse(y_true, y_pred):\n",
    "    return tf.losses.mean_squared_error(y_true,y_pred)\n",
    "\n",
    "# SGD Optimizer\n",
    "optimizer = tf.optimizers.SGD(learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-22T21:09:02.885578Z",
     "start_time": "2021-01-22T21:09:01.589453Z"
    }
   },
   "outputs": [],
   "source": [
    "history = []\n",
    "start = time.time()\n",
    "\n",
    "# Start training\n",
    "for epoch in range(1, epochs + 1):\n",
    "    \n",
    "    # Begin GradientTape and optimise\n",
    "    with tf.GradientTape() as g:\n",
    "        pred = predict(data_X)\n",
    "        loss = mse(data_Y, pred)\n",
    "\n",
    "    # Compute dw, db\n",
    "    gradients = g.gradient(loss, [w,b])\n",
    "    \n",
    "    # Update w and b\n",
    "    optimizer.apply_gradients(zip(gradients, [w,b]))\n",
    "    \n",
    "    # Monitor training / display steps\n",
    "    if epoch % display_step == 0:\n",
    "        pred = predict(data_X)\n",
    "        loss = mse(pred, data_Y)\n",
    "        history.append(np.array(w * data_X + b))\n",
    "        print(\"Epoch: %i, Loss: %f, w: %f, b: %f\" % (epoch, loss, w.numpy(), b.numpy()))\n",
    "print('Train Time: %f seconds' %(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-22T21:09:03.024803Z",
     "start_time": "2021-01-22T21:09:02.888578Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,6))\n",
    "\n",
    "plt.scatter(data_X,data_Y, label=\"Data\")\n",
    "# for i in range(len(history)):\n",
    "#     plt.plot(data_X,history[i], c='k',label=str((i+1)*display_step)+\" epoch\", alpha = (i+1)/(i+5))\n",
    "plt.plot(data_X,history[-1],'k')\n",
    "plt.xlabel('H2R')\n",
    "plt.ylabel('lnMFR')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![exercise](https://apmonitor.com/che263/uploads/Begin_Python/exercise.png)\n",
    "\n",
    "### Pytorch Linear Regression\n",
    "\n",
    "PyTorch is best known for nonlinear regression such as with Deep Learning. This tutorial shows how to use PyTorch for a simple linear regression. There are better packages for linear regression. See also [Numpy vs PyTorch: Linear Regression from scratch](https://medium.com/analytics-vidhya/numpy-vs-pytorch-linear-regression-from-scratch-452a121fb0e8)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-22T21:09:03.040590Z",
     "start_time": "2021-01-22T21:09:03.026581Z"
    }
   },
   "outputs": [],
   "source": [
    "data_X = data_X.reshape(len(data_X),1)\n",
    "data_Y = data_Y.reshape(len(data_Y),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-22T21:09:03.358581Z",
     "start_time": "2021-01-22T21:09:03.042580Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "class linearRegression(torch.nn.Module):\n",
    "    def __init__(self, inputSize, outputSize):\n",
    "        super(linearRegression, self).__init__()\n",
    "        self.linear = torch.nn.Linear(inputSize, outputSize)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-22T21:09:03.374581Z",
     "start_time": "2021-01-22T21:09:03.359520Z"
    }
   },
   "outputs": [],
   "source": [
    "inputDim = 1        # takes variable 'x' \n",
    "outputDim = 1       # takes variable 'y'\n",
    "learningRate = 0.01 \n",
    "epochs = 100\n",
    "\n",
    "model = linearRegression(inputDim, outputDim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-22T21:09:03.390581Z",
     "start_time": "2021-01-22T21:09:03.375496Z"
    }
   },
   "outputs": [],
   "source": [
    "criterion = torch.nn.MSELoss() \n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learningRate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-22T21:09:03.533507Z",
     "start_time": "2021-01-22T21:09:03.391504Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    # Converting inputs and labels to Variable\n",
    "    inputs = Variable(torch.from_numpy(data_X).float())\n",
    "    labels = Variable(torch.from_numpy(data_Y).float())\n",
    "\n",
    "    # Clear gradient buffers because we don't want any gradient from previous epoch to carry forward, dont want to cummulate gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # get output from the model, given the inputs\n",
    "    outputs = model(inputs)\n",
    "\n",
    "    # get loss for the predicted output\n",
    "    loss = criterion(outputs, labels)\n",
    "    print(loss)\n",
    "    # get gradients w.r.t to parameters\n",
    "    loss.backward()\n",
    "\n",
    "    # update parameters\n",
    "    optimizer.step()\n",
    "\n",
    "#     print('epoch {}, loss {}'.format(epoch, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-22T21:09:03.705468Z",
     "start_time": "2021-01-22T21:09:03.536468Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with torch.no_grad(): # we don't need gradients in the testing phase\n",
    "    predicted = model(Variable(torch.from_numpy(data_X).float())).data.numpy()\n",
    "#     print(predicted)\n",
    "\n",
    "fig = plt.figure(figsize=(10,6))\n",
    "plt.scatter(data_X, data_Y)\n",
    "plt.plot(data_X, predicted, 'k')\n",
    "plt.xlabel('H2R')\n",
    "plt.ylabel('lnMFR')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
