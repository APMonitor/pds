{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thermophysical Property Prediction\n",
    "\n",
    "Empirical regression has limitations, especially when predictions are requested outside of the training region. Physics-based information can overcome this limitation by including fundamental engineering knowledge such as constraints during the training process. Constraints can be important physics-based information to improve machine learned predictions. Constraints are demonstrated on linear regression with sample data. The purpose of this [Thermophysical Property Case Study](https://apmonitor.com/pds/index.php/Main/ThermophysicalProperties) is to evaluate the performance of a neural network with and without constraints for thermophysical property predictions.\n",
    "\n",
    "<img align=left width=400px src='https://apmonitor.com/pds/uploads/Main/thermophysical_properties.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression with and without Constraints\n",
    "\n",
    "Below is an example of linear regression with and without a lower bound constraint on a parameter. In this case, the constraint is on the slope ($a\\ge0$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gekko import GEKKO\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# define data\n",
    "x = np.random.rand(100) + np.linspace(0,100,100)\n",
    "y = np.random.rand(100) - 2*np.linspace(0,1,100)\n",
    "\n",
    "# linear regression model with Gekko\n",
    "m = GEKKO()\n",
    "\n",
    "# unknown parameters\n",
    "a,b = m.Array(m.FV,2)\n",
    "a.STATUS = 1; b.STATUS = 1\n",
    "\n",
    "# variables and parameters\n",
    "yp = m.Var()\n",
    "ym = m.Param(y)\n",
    "xm = m.Param(x)\n",
    "\n",
    "# equations and objective\n",
    "m.Equation(yp == a*xm + b)\n",
    "m.Minimize((yp-ym)**2)\n",
    "\n",
    "# solve\n",
    "m.options.IMODE = 2\n",
    "m.solve(disp=False)\n",
    "p1 = [a.value[0],b.value[0]]\n",
    "\n",
    "print('Slope:', p1[0])\n",
    "print('Intercept:', p1[1])\n",
    "\n",
    "# add constraint to the slope (>=0)\n",
    "a.LOWER = 0.0\n",
    "m.solve(disp=False)\n",
    "p2 = [a.value[0],b.value[0]]\n",
    "\n",
    "print('Slope:', p2[0])\n",
    "print('Intercept:', p2[1])\n",
    "\n",
    "# plot results\n",
    "plt.plot(x,y,'r.')\n",
    "plt.plot(x,np.polyval(p1,x),label='Unconstrained')\n",
    "plt.plot(x,np.polyval(p2,x),label='Constrained (slope>=0)')\n",
    "plt.ylabel('y'); plt.xlabel('x'); plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Thermophysical Properties\n",
    "\n",
    "__Background__: Parachor values are a factor in the prediction of several thermophysical properties such as surface tension and thermal conductivity. The parachor value ($P$) is used to predict surface tension with the difference between the density of saturated liquid $\\rho_L$ and saturated vapor $\\rho_V$ at the temperature of interest.\n",
    "\n",
    "$\\sigma = \\left(P\\left(\\rho_L-\\rho_V\\right)\\right)^4$\n",
    "\n",
    "Surface tension and thermal conductivity are two specific properties that need improved predictions. A more accurate predictor of the parachor value (P) is an important step to improve those thermophysical properties. Most deep learning methods use a limited set of activation functions (ReLU, sigmoid, tanh, and linear) and perform unconstrained regression to minimize a loss function. The purpose of this case study is to explore the addition of physics-based information in the fitting process. This may include the use of new types of activation functions or constraints on the adjustable weights. The data for this case study is from Gharagheizi, et. al. (2011) who explored deep learning (a multi-layered neural network) to improve parachor predictions for 277 compounds from 40 functional groups.\n",
    "\n",
    "- Name: The common chemical name\n",
    "- Formula: Chemical formula of the compound\n",
    "- CASN: Chemical Abstracts Service Registry Number\n",
    "- Family: Chemical family of the compound\n",
    "- Parachor: Estimate of parachor value\n",
    "- Grp1-Grp40: Number of functional groups in the compound\n",
    "\n",
    "__Objective__: Develop a prediction of the parachar from the chemical compound data set. Report the correlation coefficient (R2) for predicting Parachor in the test set. Randomly select values that split the data into a train (80%) and test (20%) set. Use Linear Regression and Neural Network (Deep Learning) with constraints. The solutions for regression without constraints or feature engineering are provided in this notebook. For the constrained cases, enforce a positive parachor contribution for each group. Discuss the performance of each on the train and test sets. Submit source code and a summary memo (max 2 pages) of your results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data\n",
    "\n",
    "[Chemical Compound Data Set](http://apmonitor.com/pds/uploads/Main/thermo.txt)\n",
    "\n",
    "```python\n",
    "url = 'http://apmonitor.com/pds/uploads/Main/thermo.txt'\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://apmonitor.com/pds/uploads/Main/thermo.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression without Constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = pd.read_csv(url)\n",
    "\n",
    "# input\n",
    "d = np.array(data)[:,-40:]\n",
    "d = np.array(d,dtype=float)\n",
    "\n",
    "d_train = d[0:205]\n",
    "d_valid = d[205:]\n",
    "\n",
    "# measured output\n",
    "meas = np.array(data['Parachor'])\n",
    "meas_train = meas[0:205]\n",
    "meas_valid = meas[205:]\n",
    "\n",
    "# linear regression\n",
    "#  d * b = p\n",
    "#  (d^T * d) * b = (d^T * meas)\n",
    "#  A * b = rhs\n",
    "A = np.dot(d_train.T,d_train)\n",
    "rhs = np.dot(d_train.T,meas_train)\n",
    "# solve for\n",
    "#  b = inv(d^T*d)*d^T*p\n",
    "b = np.linalg.solve(A,rhs)\n",
    "\n",
    "# predicted output\n",
    "pred_train = np.dot(d_train,b)\n",
    "pred_valid = np.dot(d_valid,b)\n",
    "\n",
    "print('ms_abs train')\n",
    "print(np.sum(np.abs((meas_train-pred_train)/meas_train)/(len(meas_train))))\n",
    "print('ms_abs validate')\n",
    "print(np.sum(np.abs((meas_valid-pred_valid)/meas_valid)/(len(meas_valid))))\n",
    "\n",
    "# parity plot\n",
    "plt.loglog([80,2000],[80,2000],'k-')\n",
    "plt.loglog(meas_train,pred_train,'b.',label='Linear (Train)')\n",
    "plt.loglog(meas_valid,pred_valid,'r.',label='Linear (Validate)')\n",
    "plt.legend()\n",
    "plt.xlabel('Measured')\n",
    "plt.ylabel('Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network (Deep Learning) without Constraints in Keras / TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import *\n",
    "import matplotlib.pyplot as plt  \n",
    "\n",
    "#################################################################\n",
    "### Import Data #################################################\n",
    "#################################################################\n",
    "\n",
    "data = pd.read_csv(url)\n",
    "\n",
    "# input\n",
    "d = np.array(data)[:,-40:]\n",
    "d = np.array(d,dtype=float)\n",
    "x_train = d[0:205]\n",
    "x_valid = d[205:]\n",
    "\n",
    "# measured output\n",
    "meas = np.array(data['Parachor'])\n",
    "y_train = meas[0:205]\n",
    "y_valid = meas[205:]\n",
    "\n",
    "train = np.vstack((x_train.T,y_train)).T\n",
    "valid = np.vstack((x_valid.T,y_valid)).T\n",
    "\n",
    "#################################################################\n",
    "### Scale data ##################################################\n",
    "#################################################################\n",
    "\n",
    "# scale values to 0 to 1 for the ANN to work well\n",
    "s = MinMaxScaler(feature_range=(0,1))\n",
    "\n",
    "# scale training and test data\n",
    "sc_train = s.fit_transform(train)\n",
    "xs_train = sc_train[:,0:-1]\n",
    "ys_train = sc_train[:,-1]\n",
    "\n",
    "sc_valid = s.transform(valid)\n",
    "xs_valid = sc_valid[:,0:-1]\n",
    "ys_valid = sc_valid[:,-1]\n",
    "\n",
    "#################################################################\n",
    "### Train model #################################################\n",
    "#################################################################\n",
    "\n",
    "# create neural network model\n",
    "model = Sequential()\n",
    "model.add(Dense(40, input_dim=40, activation='linear'))\n",
    "model.add(Dense(40, activation='linear'))\n",
    "model.add(Dense(5, activation='tanh'))\n",
    "model.add(Dense(5, activation='linear'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"adam\")\n",
    "\n",
    "# load training data\n",
    "X1 = xs_train\n",
    "Y1 = ys_train\n",
    "\n",
    "# train the model\n",
    "model.fit(X1,Y1,epochs=200,verbose=0,shuffle=True)\n",
    "\n",
    "#################################################################\n",
    "### Test model ##################################################\n",
    "#################################################################\n",
    "\n",
    "# load test data\n",
    "X2 = xs_valid\n",
    "Y2 = ys_valid\n",
    "\n",
    "# test the model\n",
    "mse_train = model.evaluate(X1,Y1, verbose=1)\n",
    "mse_valid = model.evaluate(X2,Y2, verbose=1)\n",
    "\n",
    "print('Mean Squared Error (Train): ', mse_train)\n",
    "print('Mean Squared Error (Valid): ', mse_valid)\n",
    "\n",
    "#################################################################\n",
    "### Predictions Outside Training Region #########################\n",
    "#################################################################\n",
    "\n",
    "# predict\n",
    "Y1P = model.predict(X1)\n",
    "Y2P = model.predict(X2)\n",
    "\n",
    "# unscale for plotting and analysis\n",
    "ymin = s.min_[-1]\n",
    "yrange = s.scale_[-1]\n",
    "\n",
    "Y1u = (Y1-ymin)/yrange\n",
    "Y1Pu = (Y1P-ymin)/yrange\n",
    "\n",
    "Y2u = (Y2-ymin)/yrange\n",
    "Y2Pu = (Y2P-ymin)/yrange\n",
    "\n",
    "sae1 = 0.0\n",
    "for i in range(len(Y1u)):\n",
    "    sae1 += np.abs(Y1u[i]-Y1Pu[i][0])/Y1u[i]\n",
    "sae1 = sae1 / len(Y1u)\n",
    "\n",
    "sae2 = 0.0\n",
    "for i in range(len(Y2u)):\n",
    "    sae2 += np.abs(Y2u[i]-Y2Pu[i][0])/Y2u[i]\n",
    "sae2 = sae2 / len(Y2u)\n",
    "\n",
    "# mean sum abs difference\n",
    "print('Mean sum abs diff - Training ' + str(sae1))\n",
    "print('Mean sum abs diff - Validate ' + str(sae2))\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(Y1u, Y1Pu, 'b.',label='train')\n",
    "plt.plot(Y2u, Y2Pu, 'r.',label='validate')\n",
    "plt.xlabel('Measured')\n",
    "plt.ylabel('Predicted')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network (Deep Learning) without Constraints in Gekko"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gekko import GEKKO\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt  \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = pd.read_csv(url)\n",
    "\n",
    "# Size with hyperbolic tangent function\n",
    "nin = 40  # inputs\n",
    "n1 = 1   # hidden layer 1 (linear)\n",
    "n2 = 5   # hidden layer 2 (nonlinear)\n",
    "n3 = 1   # hidden layer 3 (linear)\n",
    "nout = 1 # outputs\n",
    "\n",
    "# input\n",
    "d = np.array(data)[:,-40:]\n",
    "d = np.array(d,dtype=float)\n",
    "\n",
    "s_in_min = np.min(d,axis=0)\n",
    "s_in_range = np.max(d,axis=0)-np.min(d,axis=0)\n",
    "ds = np.empty_like(d)\n",
    "for i in range(nin):\n",
    "    for j in range(np.size(d,0)):\n",
    "        ds[j,i] = (d[j,i]-s_in_min[i])/s_in_range[i]\n",
    "ds_train = ds[0:205]\n",
    "ds_valid = ds[205:]\n",
    "\n",
    "# measured output\n",
    "meas = np.array(data['Parachor'])\n",
    "s_out_min = np.min(meas)\n",
    "s_out_range = np.max(meas)-np.min(meas)\n",
    "meass = np.empty_like(meas)\n",
    "for j in range(len(meas)):\n",
    "    meass[j] = (meas[j] - s_out_min) / s_out_range \n",
    "# scaled values\n",
    "meas_train = meass[0:205]\n",
    "meas_valid = meass[205:]\n",
    "# unscaled values\n",
    "umeas_train = meas[0:205]\n",
    "umeas_valid = meas[205:]\n",
    "\n",
    "# Initialize gekko\n",
    "train = GEKKO(remote=False) \n",
    "test = GEKKO(remote=False)\n",
    "\n",
    "model = [train,test]\n",
    "\n",
    "for m in model:\n",
    "    # input(s)\n",
    "    m.inpt = [m.Param() for i in range(nin)]\n",
    "\n",
    "    # layer 1\n",
    "    m.w1 = m.Array(m.FV, (nin,n1))\n",
    "    m.l1 = [sum([m.Intermediate(m.w1[j,i]*m.inpt[j]) for j in range(nin)]) for i in range(n1)]\n",
    "\n",
    "    # layer 2\n",
    "    m.w2 = m.Array(m.FV, (n1,n2))\n",
    "    m.l2 = [m.Intermediate(sum([m.tanh(m.w2[j,i]*m.l1[j]) \\\n",
    "                           for j in range(n1)])) for i in range(n2)]\n",
    "\n",
    "    # layer 3\n",
    "    m.w3 = m.Array(m.FV, (n2,n3))\n",
    "    m.l3 = [m.Intermediate(sum([m.w3[j,i]*m.l2[j] \\\n",
    "            for j in range(n2)])) for i in range(n3)]\n",
    "\n",
    "    # output(s)\n",
    "    m.outpt = m.CV()\n",
    "    m.Equation(m.outpt==sum([m.l3[i] for i in range(n3)]))\n",
    "\n",
    "    # flatten matrices\n",
    "    m.w1 = m.w1.flatten()\n",
    "    m.w2 = m.w2.flatten()\n",
    "    m.w3 = m.w3.flatten()\n",
    "\n",
    "# Fit parameter weights\n",
    "m = train\n",
    "for i in range(nin):\n",
    "    m.inpt[i].value=ds_train[:,i]\n",
    "m.outpt.value=meas_train\n",
    "m.outpt.FSTATUS = 1\n",
    "for i in range(len(m.w1)):\n",
    "    m.w1[i].FSTATUS=1\n",
    "    m.w1[i].STATUS=1\n",
    "    m.w1[i].MEAS=1.0\n",
    "    # add constraint\n",
    "    # m.w1[i].LOWER = 0.0\n",
    "for i in range(len(m.w2)):\n",
    "    m.w2[i].STATUS=1\n",
    "    m.w2[i].FSTATUS=1\n",
    "    m.w2[i].MEAS=0.5\n",
    "for i in range(len(m.w3)):\n",
    "    m.w3[i].FSTATUS=1\n",
    "    m.w3[i].STATUS=1\n",
    "    m.w3[i].MEAS=1.0\n",
    "m.options.IMODE = 2\n",
    "#m.options.OTOL = 1e-2\n",
    "m.options.SOLVER = 1\n",
    "m.options.EV_TYPE = 2\n",
    "m.options.MAX_ITER = 1000\n",
    "m.solve(disp=False)\n",
    "\n",
    "# Test sample points\n",
    "m = test\n",
    "for i in range(len(m.w1)):\n",
    "    m.w1[i].MEAS=train.w1[i].NEWVAL\n",
    "    m.w1[i].FSTATUS = 1\n",
    "for i in range(len(m.w2)):\n",
    "    m.w2[i].MEAS=train.w2[i].NEWVAL\n",
    "    m.w2[i].FSTATUS = 1\n",
    "for i in range(len(m.w3)):\n",
    "    m.w3[i].MEAS=train.w3[i].NEWVAL\n",
    "    m.w3[i].FSTATUS = 1\n",
    "for i in range(nin):\n",
    "    m.inpt[i].value=ds_valid[:,i]\n",
    "m.options.IMODE = 2\n",
    "m.options.SOLVER = 1\n",
    "m.solve(disp=False)\n",
    "\n",
    "# unscale\n",
    "pred_train = np.empty_like(meas_train)\n",
    "for i in range(len(pred_train)):\n",
    "    pred_train[i] = train.outpt.value[i] * s_out_range + s_out_min\n",
    "\n",
    "pred_valid = np.empty_like(meas_valid)\n",
    "for i in range(len(pred_valid)):\n",
    "    pred_valid[i] = test.outpt.value[i] * s_out_range + s_out_min\n",
    "\n",
    "print('ms_abs train')\n",
    "print(np.sum(np.abs((umeas_train-pred_train)/umeas_train)/(len(umeas_train))))\n",
    "print('ms_abs validate')\n",
    "print(np.sum(np.abs((umeas_valid-pred_valid)/umeas_valid)/(len(umeas_valid))))\n",
    "\n",
    "# parity plot\n",
    "plt.loglog([80,2000],[80,2000],'k-')\n",
    "plt.loglog(umeas_train,pred_train,'b.',label='ANN (Train)')\n",
    "plt.loglog(umeas_valid,pred_valid,'r.',label='ANN (Validate)')\n",
    "plt.legend()\n",
    "plt.xlabel('Measured')\n",
    "plt.ylabel('Predicted')\n",
    "plt.savefig('ann_gekko.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print neural network weights. Count the number of negative weights in `w1` (the first layer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test sample points\n",
    "m = test\n",
    "for i in range(len(m.w1)):\n",
    "    print('w1['+str(i)+']: '+str(m.w1[i].MEAS))\n",
    "for i in range(len(m.w2)):\n",
    "    print('w2['+str(i)+']: '+str(m.w2[i].MEAS))\n",
    "for i in range(len(m.w3)):\n",
    "    print('w3['+str(i)+']: '+str(m.w3[i].MEAS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constrained Regression \n",
    "\n",
    "Add a constraint to the Gekko source with `m.w1[i].LOWER = 0.0` to enforce `w1` positive parameter weights. Alternatively, add a [positive weight constraint](https://keras.io/api/layers/constraints/) to the first layer in the Keras / TensorFlow source code. Report results on $R^2$, Mean Absolute Error, or similar performance metric for constrained and unconstrained results.\n",
    "\n",
    "<img align=left width=550px src='https://apmonitor.com/pds/uploads/Main/parachor_constrained.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
